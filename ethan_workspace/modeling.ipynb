{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effective-million",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you have a possoint distribution apply an anscombe transformation to make it normal\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import roc_auc_score, r2_score, accuracy_score\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Masking, LSTM, TimeDistributed, Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return np.mean((y_pred - y_true) / y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threatened-guitar",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = pd.read_csv('raw_data/all_raw_remnant_input.csv')\n",
    "modeling_data = pd.read_csv('raw_data/all_raw_remnant_target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wireless-paris",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['directory_1', \n",
    "                         'directory_2', \n",
    "                         'directory_3', \n",
    "                         'sequence_id', \n",
    "                         'is_skill_builder', \n",
    "                         'has_due_date', \n",
    "                         'assignment_completed']\n",
    "\n",
    "continuous_features = ['time_since_last_assignment_start', \n",
    "                        'session_count_raw',\n",
    "                        'session_count_normalized', \n",
    "                        'session_count_class_percentile',\n",
    "                        'day_count_raw', \n",
    "                        'day_count_normalized', \n",
    "                        'day_count_class_percentile',\n",
    "                        'completed_problem_count_raw', \n",
    "                        'completed_problem_count_normalized',\n",
    "                        'completed_problem_count_class_percentile',\n",
    "                        'median_ln_problem_time_on_task_raw',\n",
    "                        'median_ln_problem_time_on_task_normalized',\n",
    "                        'median_ln_problem_time_on_task_class_percentile',\n",
    "                        'median_ln_problem_first_response_time_raw',\n",
    "                        'median_ln_problem_first_response_time_normalized',\n",
    "                        'median_ln_problem_first_response_time_class_percentile',\n",
    "                        'average_problem_attempt_count',\n",
    "                        'average_problem_attempt_count_normalized',\n",
    "                        'average_problem_attempt_count_class_percentile',\n",
    "                        'average_problem_answer_first',\n",
    "                        'average_problem_answer_first_normalized',\n",
    "                        'average_problem_answer_first_class_percentile',\n",
    "                        'average_problem_correctness', \n",
    "                        'average_problem_correctness_normalized',\n",
    "                        'average_problem_correctness_class_percentile',\n",
    "                        'average_problem_hint_count', \n",
    "                        'average_problem_hint_count_normalized',\n",
    "                        'average_problem_hint_count_class_percentile',\n",
    "                        'average_problem_answer_given',\n",
    "                        'average_problem_answer_given_normalized',\n",
    "                        'average_problem_answer_given_class_percentile',\n",
    "                        'time_since_last_assignment_start_cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loved-girlfriend",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Look at the distributions of all the raw inputs, or the frequency of values in the raw inputs\n",
    "\n",
    "PLOT_ROWS = 14\n",
    "PLOT_COLS = 3\n",
    "\n",
    "fig, axs = plt.subplots(PLOT_ROWS, PLOT_COLS, figsize=(20,50))\n",
    "\n",
    "offset = PLOT_ROWS * PLOT_COLS - len(input_data.columns)\n",
    "\n",
    "for i in range(len(input_data.columns)):\n",
    "    r = int((i + offset) / PLOT_COLS)\n",
    "    c = (i + offset) % PLOT_COLS\n",
    "    col = input_data.columns[i]\n",
    "    axs[r, c].hist(input_data[col].value_counts() if i < 5 else input_data[col], 50)\n",
    "    axs[r, c].set_title(col + '_value_counts' if i < 5 else col)\n",
    "fig.savefig('first_look.png', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retained-reader",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create additional features and target variables\n",
    "\n",
    "# Inverse mastery speed\n",
    "modeling_data['inverse_mastery_speed'] = modeling_data.apply(lambda x: 1 / x['problems_completed'] if x['assignment_completed'] else 0, axis=1)\n",
    "\n",
    "# An explicit feature for which cluster the time_since_last_assignment_start falls into\n",
    "clusters = 4\n",
    "times = input_data['time_since_last_assignment_start'].values.reshape(-1, 1)\n",
    "input_data['time_since_last_assignment_start_cluster'] = GaussianMixture(n_components=clusters).fit(times).predict(times)\n",
    "categorical_features.append('time_since_last_assignment_start_cluster')\n",
    "\n",
    "# A feature for whether or not there is a folder path\n",
    "input_data['custom_assignment'] = input_data['directory_1'].isna().astype(int)\n",
    "categorical_features.append('custom_assignment')\n",
    "\n",
    "# A feature for whether or not there is any problem level data\n",
    "input_data['no_problem_statsistics'] = input_data['median_ln_problem_time_on_task_raw'].isna().astype(int)\n",
    "categorical_features.append('no_problem_statsistics')\n",
    "\n",
    "# Replace NaN categorical features with -1\n",
    "input_data[categorical_features] = input_data[categorical_features].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "several-briefing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the previous assignments to the training data\n",
    "modeling_data['previous_assignments'] = None\n",
    "\n",
    "for i, row in modeling_data.iterrows():\n",
    "    row_input = input_data[(input_data['assignment_start_time'] < row['assignment_start_time']) & (input_data['student_id'] == row['student_id'])].sort_values('assignment_start_time')\n",
    "    row_input['target_sequence'] = row['target_sequence']\n",
    "    if len(row_input) > 0:\n",
    "        modeling_data.at[i, 'previous_assignments'] = row_input\n",
    "\n",
    "modeling_data = modeling_data[~modeling_data['previous_assignments'].isna()]\n",
    "categorical_features.append('target_sequence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removable-brass",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_data.to_pickle('modeling_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-university",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_data.read_pickle('modeling_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suburban-precipitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_input(df_list, one_hot_encoder=None, normalizer=None, max_sequence_length=20):\n",
    "    \n",
    "    if one_hot_encoder is None:\n",
    "        categorical_data = np.concatenate([df[categorical_features].values for df in df_list])\n",
    "        continuous_data = np.concatenate([df[continuous_features].values for df in df_list])\n",
    "        one_hot_encoder = OneHotEncoder(handle_unknown='ignore').fit(categorical_data)\n",
    "        normalizer = StandardScaler().fit(continuous_data)\n",
    "    \n",
    "    processed_input = []\n",
    "    for df in df_list:\n",
    "        categorical_data = one_hot_encoder.transform(df[categorical_features]).toarray()\n",
    "        continuous_data = np.nan_to_num(normalizer.transform(df[continuous_features]))\n",
    "        combined_data = np.concatenate([categorical_data, continuous_data], axis=1)\n",
    "        if combined_data.shape[0] >= max_sequence_length:\n",
    "            resized_data = combined_data[-max_sequence_length:,:]\n",
    "        else:\n",
    "            resized_data = np.zeros((max_sequence_length, combined_data.shape[1]))\n",
    "            resized_data[-combined_data.shape[0]:,:] = combined_data\n",
    "        processed_input.append(resized_data)\n",
    "    \n",
    "    return np.stack(processed_input), one_hot_encoder, normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "directed-massage",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "# Normalize and one hot encode the data based on the input data\n",
    "\n",
    "N_SPLITS = 5\n",
    "\n",
    "completion_acc = []\n",
    "completion_auc = []\n",
    "problems_mpe = []\n",
    "problems_r2 = []\n",
    "\n",
    "for train_index, test_index in GroupKFold(N_SPLITS).split(modeling_data, groups=modeling_data['student_id']):\n",
    "    # Create the data for training and testing\n",
    "    training_input, input_one_hot_encoder, input_normalizer = process_input(modeling_data.iloc[train_index]['previous_assignments'].tolist())\n",
    "    completion_training_target = modeling_data.iloc[train_index][['assignment_completed']].values\n",
    "    problems_training_target = modeling_data.iloc[train_index][['problems_completed']].values\n",
    "    testing_input, _, _ = process_input(modeling_data.iloc[test_index]['previous_assignments'].tolist(), input_one_hot_encoder, input_normalizer)\n",
    "    completion_testing_target = modeling_data.iloc[test_index][['assignment_completed']].values\n",
    "    problems_testing_target = modeling_data.iloc[test_index][['problems_completed']].values\n",
    "    \n",
    "    # Clear session so models don't pile up\n",
    "    keras.backend.clear_session()\n",
    "    \n",
    "    # Train model to predict completion\n",
    "    completion_model = Sequential()\n",
    "    completion_model.add(Masking(mask_value=0.0, input_shape=(training_input[0].shape)))\n",
    "    completion_model.add(LSTM(32, activation='tanh', return_sequences=False))\n",
    "    completion_model.add(Dense(completion_training_target.shape[1], activation='sigmoid'))\n",
    "    completion_model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    \n",
    "    es = [EarlyStopping(monitor='val_loss', patience=5, min_delta=0, restore_best_weights=True)]\n",
    "    completion_model.fit(training_input, completion_training_target, epochs=1000, validation_split=0.2, callbacks=es, verbose=True)\n",
    "    \n",
    "    # Train model to predict problems to mastery when assignment is completed\n",
    "    problems_training_input = training_input[completion_training_target.flatten() == 1]\n",
    "    problems_training_target = problems_training_target[completion_training_target.flatten() == 1]\n",
    "\n",
    "    problems_model = Sequential()\n",
    "    problems_model.add(Masking(mask_value=0.0, input_shape=(training_input[0].shape)))\n",
    "    problems_model.add(LSTM(32, activation='tanh', return_sequences=False))\n",
    "    problems_model.add(Dense(problems_training_target.shape[1], activation='linear'))\n",
    "    problems_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    es = [EarlyStopping(monitor='val_loss', patience=5, min_delta=0, restore_best_weights=True)]\n",
    "    problems_model.fit(problems_training_input, problems_training_target, epochs=1000, validation_split=0.2, callbacks=es, verbose=True)\n",
    "    \n",
    "    # Measure the quality of the \n",
    "    completion_testing_output = completion_model.predict(testing_input)\n",
    "    completion_acc.append(accuracy_score(completion_testing_target, completion_testing_output > 0.5))\n",
    "    completion_auc.append(roc_auc_score(completion_testing_target, completion_testing_output))\n",
    "\n",
    "    problems_testing_output = problems_model.predict(testing_input[completion_testing_output.flatten() > 0.5])\n",
    "    problems_testing_target = problems_testing_target[completion_testing_output.flatten() > 0.5]\n",
    "    problems_mpe.append(mean_absolute_percentage_error(problems_testing_target, problems_testing_output))\n",
    "    problems_r2.append(r2_score(problems_testing_target, problems_testing_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elegant-coalition",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'completion accuracy: {np.mean(completion_acc)}, completion auc: {np.mean(completion_auc)}')\n",
    "print(f'problems to mastery mean percent error: {np.mean(problems_mpe)}, problems to mastery r^2: {np.mean(problems_r2)}')\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(completion_testing_target, completion_testing_output)\n",
    "plt.show()\n",
    "\n",
    "completion_truth = completion_testing_target[completion_testing_output.flatten() > 0.5]\n",
    "plt.figure()\n",
    "plt.scatter(problems_testing_target[completion_truth.flatten() == 1], problems_testing_output[completion_truth.flatten() == 1])\n",
    "plt.scatter(problems_testing_target[completion_truth.flatten() == 0], problems_testing_output[completion_truth.flatten() == 0])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adverse-concrete",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

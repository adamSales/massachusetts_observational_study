{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Input, RepeatVector, Dense, Bidirectional, LSTM, Concatenate\n",
    "\n",
    "# Hide GPU from visible devices\n",
    "tf.config.set_visible_devices([], 'GPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "521 37 37 447 521\n"
     ]
    }
   ],
   "source": [
    "# Get groups of schools\n",
    "\n",
    "matches = pd.read_csv('input_data/matches.csv', dtype=str)\n",
    "treatment_schools = matches[matches['trt'] == '1']['school_code'].tolist()\n",
    "control_schools = matches[(matches['trt'] != '1') & (~matches['pairmatch'].isna())]['school_code'].tolist()\n",
    "remnant_schools = matches[matches['pairmatch'].isna()]['school_code'].tolist()\n",
    "print(len(matches), len(treatment_schools), len(control_schools), len(remnant_schools), len(treatment_schools) + len(control_schools) + len(remnant_schools))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(447, 69) (447, 5, 51) (447,) (447,)\n",
      "(74, 69) (74, 5, 51) (74,) (74,)\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "\n",
    "mass_doe_data = pd.read_csv('input_data/mass_doe_data.csv', dtype=str).astype(str)\n",
    "mass_doe_data = mass_doe_data.set_index('school_code')\n",
    "float_columns = [c for c in mass_doe_data if c != 'prior_performance']\n",
    "mass_doe_data[float_columns] = mass_doe_data[float_columns].astype(float)\n",
    "mass_doe_data['prior_performance'] = mass_doe_data['prior_performance'].apply(lambda x: np.array(eval(x.replace('nan', 'np.nan'))))\n",
    "mass_doe_data = mass_doe_data.sort_values('school_code')\n",
    "\n",
    "performance_data = pd.read_csv('input_data/performance.csv', dtype=str).astype(str)\n",
    "performance_data = performance_data.set_index('school_code')\n",
    "performance_data = performance_data.astype(float)\n",
    "performance_data = performance_data / 100\n",
    "performance_data = performance_data.sort_values('school_code')\n",
    "\n",
    "# Remnant data\n",
    "\n",
    "remnant_mass_doe_data = mass_doe_data[mass_doe_data.index.isin(remnant_schools)]\n",
    "remnant_performance_data = performance_data[performance_data.index.isin(remnant_schools)]\n",
    "remnant_demographics = remnant_mass_doe_data.drop(columns=['prior_performance']).values\n",
    "remnant_prior_performance = np.array(remnant_mass_doe_data['prior_performance'].tolist())\n",
    "remnant_performance = remnant_performance_data['performance'].values\n",
    "remnant_school_codes = np.array(remnant_performance_data.index)\n",
    "print(remnant_demographics.shape, remnant_prior_performance.shape, remnant_performance.shape, remnant_school_codes.shape)\n",
    "\n",
    "# Experiment data\n",
    "\n",
    "experiment_mass_doe_data = mass_doe_data[mass_doe_data.index.isin(treatment_schools + control_schools)]\n",
    "experiment_performance_data = performance_data[performance_data.index.isin(treatment_schools + control_schools)]\n",
    "experiment_demographics = experiment_mass_doe_data.drop(columns=['prior_performance']).values\n",
    "experiment_prior_performance = np.array(experiment_mass_doe_data['prior_performance'].tolist())\n",
    "experiment_performance = experiment_performance_data['performance'].values\n",
    "experiment_school_codes = np.array(experiment_performance_data.index)\n",
    "print(experiment_demographics.shape, experiment_prior_performance.shape, experiment_performance.shape, experiment_school_codes.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "19/19 [==============================] - 7s 50ms/step - loss: 0.0175 - val_loss: 0.0295\n",
      "Epoch 2/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0091 - val_loss: 0.0273\n",
      "Epoch 3/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0075 - val_loss: 0.0267\n",
      "Epoch 4/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0067 - val_loss: 0.0269\n",
      "Epoch 5/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0051 - val_loss: 0.0287\n",
      "Epoch 6/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0052 - val_loss: 0.0247\n",
      "Epoch 7/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0052 - val_loss: 0.0251\n",
      "Epoch 8/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0037 - val_loss: 0.0283\n",
      "Epoch 9/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0041 - val_loss: 0.0241\n",
      "Epoch 10/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.0041 - val_loss: 0.0271\n",
      "Epoch 11/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0036 - val_loss: 0.0236\n",
      "Epoch 12/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0045 - val_loss: 0.0245\n",
      "Epoch 13/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0038 - val_loss: 0.0288\n",
      "Epoch 14/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0037 - val_loss: 0.0264\n",
      "Epoch 15/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0029 - val_loss: 0.0262\n",
      "Epoch 16/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0032 - val_loss: 0.0260\n",
      "Epoch 17/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0027 - val_loss: 0.0290\n",
      "Epoch 18/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0025 - val_loss: 0.0291\n",
      "Epoch 19/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0027 - val_loss: 0.0306\n",
      "Epoch 20/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0026 - val_loss: 0.0277\n",
      "Epoch 21/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0025 - val_loss: 0.0319\n",
      "Epoch 1/1000\n",
      "19/19 [==============================] - 6s 50ms/step - loss: 0.0212 - val_loss: 0.0337\n",
      "Epoch 2/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0095 - val_loss: 0.0313\n",
      "Epoch 3/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0078 - val_loss: 0.0310\n",
      "Epoch 4/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0064 - val_loss: 0.0304\n",
      "Epoch 5/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0069 - val_loss: 0.0306\n",
      "Epoch 6/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0052 - val_loss: 0.0342\n",
      "Epoch 7/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0048 - val_loss: 0.0282\n",
      "Epoch 8/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0044 - val_loss: 0.0314\n",
      "Epoch 9/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0046 - val_loss: 0.0306\n",
      "Epoch 10/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0043 - val_loss: 0.0330\n",
      "Epoch 11/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0037 - val_loss: 0.0367\n",
      "Epoch 12/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0035 - val_loss: 0.0382\n",
      "Epoch 13/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0033 - val_loss: 0.0311\n",
      "Epoch 14/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0032 - val_loss: 0.0347\n",
      "Epoch 15/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0033 - val_loss: 0.0400\n",
      "Epoch 16/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0040 - val_loss: 0.0334\n",
      "Epoch 17/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0035 - val_loss: 0.0363\n",
      "Epoch 1/1000\n",
      "19/19 [==============================] - 7s 50ms/step - loss: 0.0183 - val_loss: 0.0296\n",
      "Epoch 2/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.0091 - val_loss: 0.0333\n",
      "Epoch 3/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0083 - val_loss: 0.0259\n",
      "Epoch 4/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0071 - val_loss: 0.0302\n",
      "Epoch 5/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0063 - val_loss: 0.0277\n",
      "Epoch 6/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0053 - val_loss: 0.0321\n",
      "Epoch 7/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0050 - val_loss: 0.0288\n",
      "Epoch 8/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0047 - val_loss: 0.0315\n",
      "Epoch 9/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0050 - val_loss: 0.0295\n",
      "Epoch 10/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0043 - val_loss: 0.0331\n",
      "Epoch 11/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0042 - val_loss: 0.0322\n",
      "Epoch 12/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0035 - val_loss: 0.0303\n",
      "Epoch 13/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.0041 - val_loss: 0.0311\n",
      "Epoch 1/1000\n",
      "19/19 [==============================] - 6s 49ms/step - loss: 0.0196 - val_loss: 0.0313\n",
      "Epoch 2/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0088 - val_loss: 0.0250\n",
      "Epoch 3/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0072 - val_loss: 0.0288\n",
      "Epoch 4/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0072 - val_loss: 0.0320\n",
      "Epoch 5/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0066 - val_loss: 0.0278\n",
      "Epoch 6/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0053 - val_loss: 0.0286\n",
      "Epoch 7/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0046 - val_loss: 0.0316\n",
      "Epoch 8/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0047 - val_loss: 0.0286\n",
      "Epoch 9/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0047 - val_loss: 0.0331\n",
      "Epoch 10/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0045 - val_loss: 0.0316\n",
      "Epoch 11/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0039 - val_loss: 0.0339\n",
      "Epoch 12/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0036 - val_loss: 0.0305\n",
      "Epoch 1/1000\n",
      "19/19 [==============================] - 7s 50ms/step - loss: 0.0187 - val_loss: 0.0316\n",
      "Epoch 2/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0094 - val_loss: 0.0300\n",
      "Epoch 3/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0077 - val_loss: 0.0285\n",
      "Epoch 4/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0070 - val_loss: 0.0279\n",
      "Epoch 5/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0050 - val_loss: 0.0274\n",
      "Epoch 6/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0056 - val_loss: 0.0282\n",
      "Epoch 7/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0057 - val_loss: 0.0290\n",
      "Epoch 8/1000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.0046 - val_loss: 0.0297\n",
      "Epoch 9/1000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.0049 - val_loss: 0.0283\n",
      "Epoch 10/1000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.0043 - val_loss: 0.0281\n",
      "Epoch 11/1000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.0043 - val_loss: 0.0309\n",
      "Epoch 12/1000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.0035 - val_loss: 0.0299\n",
      "Epoch 13/1000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.0038 - val_loss: 0.0337\n",
      "Epoch 14/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0035 - val_loss: 0.0326\n",
      "Epoch 15/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0034 - val_loss: 0.0300\n",
      "Epoch 1/1000\n",
      "19/19 [==============================] - 7s 50ms/step - loss: 0.0191 - val_loss: 0.0303\n",
      "Epoch 2/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0101 - val_loss: 0.0321\n",
      "Epoch 3/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0070 - val_loss: 0.0280\n",
      "Epoch 4/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0062 - val_loss: 0.0336\n",
      "Epoch 5/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0054 - val_loss: 0.0312\n",
      "Epoch 6/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0061 - val_loss: 0.0307\n",
      "Epoch 7/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0049 - val_loss: 0.0289\n",
      "Epoch 8/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0048 - val_loss: 0.0306\n",
      "Epoch 9/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0049 - val_loss: 0.0324\n",
      "Epoch 10/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0048 - val_loss: 0.0263\n",
      "Epoch 11/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0040 - val_loss: 0.0312\n",
      "Epoch 12/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0033 - val_loss: 0.0319\n",
      "Epoch 13/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0033 - val_loss: 0.0316\n",
      "Epoch 14/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0036 - val_loss: 0.0353\n",
      "Epoch 15/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0030 - val_loss: 0.0317\n",
      "Epoch 16/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0029 - val_loss: 0.0304\n",
      "Epoch 17/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0027 - val_loss: 0.0301\n",
      "Epoch 18/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0024 - val_loss: 0.0305\n",
      "Epoch 19/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0025 - val_loss: 0.0332\n",
      "Epoch 20/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0029 - val_loss: 0.0275\n",
      "Epoch 1/1000\n",
      "19/19 [==============================] - 6s 50ms/step - loss: 0.0185 - val_loss: 0.0332\n",
      "Epoch 2/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0105 - val_loss: 0.0313\n",
      "Epoch 3/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0091 - val_loss: 0.0263\n",
      "Epoch 4/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0067 - val_loss: 0.0239\n",
      "Epoch 5/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0054 - val_loss: 0.0266\n",
      "Epoch 6/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0043 - val_loss: 0.0273\n",
      "Epoch 7/1000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.0046 - val_loss: 0.0247\n",
      "Epoch 8/1000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.0045 - val_loss: 0.0257\n",
      "Epoch 9/1000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.0040 - val_loss: 0.0241\n",
      "Epoch 10/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0037 - val_loss: 0.0259\n",
      "Epoch 11/1000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.0034 - val_loss: 0.0303\n",
      "Epoch 12/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0038 - val_loss: 0.0318\n",
      "Epoch 13/1000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.0030 - val_loss: 0.0317\n",
      "Epoch 14/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0031 - val_loss: 0.0290\n",
      "Epoch 1/1000\n",
      "19/19 [==============================] - 6s 50ms/step - loss: 0.0190 - val_loss: 0.0307\n",
      "Epoch 2/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0090 - val_loss: 0.0272\n",
      "Epoch 3/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0073 - val_loss: 0.0301\n",
      "Epoch 4/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0070 - val_loss: 0.0265\n",
      "Epoch 5/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0051 - val_loss: 0.0307\n",
      "Epoch 6/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0054 - val_loss: 0.0298\n",
      "Epoch 7/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0046 - val_loss: 0.0339\n",
      "Epoch 8/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0050 - val_loss: 0.0316\n",
      "Epoch 9/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0042 - val_loss: 0.0329\n",
      "Epoch 10/1000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.0042 - val_loss: 0.0351\n",
      "Epoch 11/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0045 - val_loss: 0.0352\n",
      "Epoch 12/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0045 - val_loss: 0.0337\n",
      "Epoch 13/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0035 - val_loss: 0.0349\n",
      "Epoch 14/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0030 - val_loss: 0.0360\n",
      "Epoch 1/1000\n",
      "19/19 [==============================] - 7s 50ms/step - loss: 0.0200 - val_loss: 0.0321\n",
      "Epoch 2/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0100 - val_loss: 0.0303\n",
      "Epoch 3/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0082 - val_loss: 0.0275\n",
      "Epoch 4/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0069 - val_loss: 0.0304\n",
      "Epoch 5/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0070 - val_loss: 0.0271\n",
      "Epoch 6/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0055 - val_loss: 0.0304\n",
      "Epoch 7/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0052 - val_loss: 0.0306\n",
      "Epoch 8/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0053 - val_loss: 0.0317\n",
      "Epoch 9/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0044 - val_loss: 0.0374\n",
      "Epoch 10/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0048 - val_loss: 0.0292\n",
      "Epoch 11/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0042 - val_loss: 0.0320\n",
      "Epoch 12/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0045 - val_loss: 0.0347\n",
      "Epoch 13/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0042 - val_loss: 0.0341\n",
      "Epoch 14/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.0042 - val_loss: 0.0366\n",
      "Epoch 15/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0034 - val_loss: 0.0343\n",
      "Epoch 1/1000\n",
      "19/19 [==============================] - 6s 49ms/step - loss: 0.0207 - val_loss: 0.0319\n",
      "Epoch 2/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0097 - val_loss: 0.0280\n",
      "Epoch 3/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0080 - val_loss: 0.0288\n",
      "Epoch 4/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0071 - val_loss: 0.0261\n",
      "Epoch 5/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0058 - val_loss: 0.0271\n",
      "Epoch 6/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0057 - val_loss: 0.0251\n",
      "Epoch 7/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0056 - val_loss: 0.0282\n",
      "Epoch 8/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0057 - val_loss: 0.0278\n",
      "Epoch 9/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0047 - val_loss: 0.0269\n",
      "Epoch 10/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0044 - val_loss: 0.0327\n",
      "Epoch 11/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0040 - val_loss: 0.0266\n",
      "Epoch 12/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0036 - val_loss: 0.0284\n",
      "Epoch 13/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0037 - val_loss: 0.0308\n",
      "Epoch 14/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0031 - val_loss: 0.0288\n",
      "Epoch 15/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0036 - val_loss: 0.0321\n",
      "Epoch 16/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0032 - val_loss: 0.0282\n",
      "MSE: 0.01508413371427219\n"
     ]
    }
   ],
   "source": [
    "# Get model quality using k-fold on remnant\n",
    "\n",
    "ff_X = remnant_demographics\n",
    "lstm_X = remnant_prior_performance\n",
    "y = remnant_performance\n",
    "i = remnant_school_codes\n",
    "\n",
    "results = []\n",
    "for train_index, test_index in KFold(n_splits=10, shuffle=True).split(ff_X, y):\n",
    "\n",
    "    # Clear session so models don't pile up\n",
    "    keras.backend.clear_session()\n",
    "\n",
    "    # Split data into training and testing splits\n",
    "    train_ff_X, test_ff_X = ff_X[train_index], ff_X[test_index]\n",
    "    train_lstm_X, test_lstm_X = lstm_X[train_index], lstm_X[test_index]\n",
    "    train_y, test_y = y[train_index], y[test_index]\n",
    "    train_i, test_i = i[train_index], i[test_index]\n",
    "\n",
    "    # Normalize the input data based on the training data distribution\n",
    "    ff_scaler = StandardScaler().fit(train_ff_X)\n",
    "    train_ff_X = np.nan_to_num(ff_scaler.transform(train_ff_X))\n",
    "    test_ff_X = np.nan_to_num(ff_scaler.transform(test_ff_X))\n",
    "\n",
    "    train_lstm_X_shape = train_lstm_X.shape\n",
    "    train_stacked_lstm_X = train_lstm_X.reshape(-1, train_lstm_X_shape[-1])\n",
    "    lstm_scaler = StandardScaler().fit(train_stacked_lstm_X)\n",
    "    train_lstm_X = np.nan_to_num(lstm_scaler.transform(train_stacked_lstm_X)).reshape(train_lstm_X_shape)\n",
    "    test_lstm_X_shape = test_lstm_X.shape\n",
    "    test_stacked_lstm_X = test_lstm_X.reshape(-1, test_lstm_X_shape[-1])\n",
    "    test_lstm_X = np.nan_to_num(lstm_scaler.transform(test_stacked_lstm_X)).reshape(test_lstm_X_shape)\n",
    "\n",
    "    # Create the neural network\n",
    "    ff_input_layer = Input(shape=train_ff_X[0].shape)\n",
    "    lstm_input_layer = Input(shape=train_lstm_X[0].shape)\n",
    "    combined_input_layer = RepeatVector(train_lstm_X.shape[1])(ff_input_layer)\n",
    "    combined_input_layer = Concatenate()([combined_input_layer, lstm_input_layer])\n",
    "\n",
    "    model = Bidirectional(LSTM(units=128, return_sequences=True, activation='tanh', dropout=0.5, recurrent_dropout=0.5))(combined_input_layer)\n",
    "    model = Bidirectional(LSTM(units=64, return_sequences=False, activation='tanh', dropout=0.5, recurrent_dropout=0.5))(model)\n",
    "    output_layer = Dense(units=1, activation='sigmoid')(model)\n",
    "\n",
    "    model = Model([ff_input_layer, lstm_input_layer], output_layer)\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    # Train the neural network\n",
    "    es = [EarlyStopping(monitor='val_loss', patience=10, min_delta=0, restore_best_weights=True)]\n",
    "    model.fit(x=[train_ff_X, train_lstm_X], y=train_y, batch_size=16, epochs=1000, validation_split=0.25, callbacks=es, verbose=1)\n",
    "\n",
    "    # Use the neural network to predict the held-out fold\n",
    "    pred_y = model.predict([test_ff_X, test_lstm_X]).flatten()\n",
    "\n",
    "    # Update predictions\n",
    "    results.append(pd.DataFrame([test_y, pred_y], columns=test_i, index=['actual_performance', 'predicted_performance']).T)\n",
    "\n",
    "results = pd.concat(results)\n",
    "results.to_csv('results/kfold_remnant_predictions.csv')\n",
    "print(f'MSE: {mean_squared_error(results.actual_performance, results.predicted_performance)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Mean Prediction MSE: 433.9361577972904\n",
    "\n",
    "(layers)     , dropout , batch size: MSE\n",
    "\n",
    "(64, 32)     , 0       , 32        : 261.0934134399656\n",
    "(32)         , 0       , 32        : 408.9117164445174\n",
    "(64, 32)     , 0.5     , 32        : 227.8827418178931\n",
    "(64, 64)     , 0.25    , 32        : 213.6578965631596\n",
    "(64, 64, 64) , 0.25    , 32        : 264.9091609712526\n",
    "(128, 64)    , 0.5     , 32        : 170.0072276619494\n",
    "(128, 64)    , 0.5     , 16        : 163.5255262041347 / 199.23285354558072 / 145.4 /\n",
    "(128, 64)    , 0.5     , 8         : 183.8387565630688\n",
    "(256, 256)   , 0.5     , 16        : 163.1883336295512\n",
    "(128, 128)   , 0.5     , 16        : 172.0166126039364\n",
    "(256, 128)   , 0.5     , 16        : 177.0513539259982\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "21/21 [==============================] - 7s 46ms/step - loss: 0.0174 - val_loss: 0.0283\n",
      "Epoch 2/1000\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.0091 - val_loss: 0.0290\n",
      "Epoch 3/1000\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.0076 - val_loss: 0.0282\n",
      "Epoch 4/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0071 - val_loss: 0.0264\n",
      "Epoch 5/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0066 - val_loss: 0.0270\n",
      "Epoch 6/1000\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.0057 - val_loss: 0.0295\n",
      "Epoch 7/1000\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.0047 - val_loss: 0.0264\n",
      "Epoch 8/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0040 - val_loss: 0.0336\n",
      "Epoch 9/1000\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.0042 - val_loss: 0.0276\n",
      "Epoch 10/1000\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.0040 - val_loss: 0.0298\n",
      "Epoch 11/1000\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.0037 - val_loss: 0.0324\n",
      "Epoch 12/1000\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.0036 - val_loss: 0.0283\n",
      "Epoch 13/1000\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.0037 - val_loss: 0.0314\n",
      "Epoch 14/1000\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.0031 - val_loss: 0.0342\n",
      "MSE: 0.004835745143614735\n"
     ]
    }
   ],
   "source": [
    "# Get predictions for experiment data\n",
    "\n",
    "train_ff_X = remnant_demographics\n",
    "train_lstm_X = remnant_prior_performance\n",
    "train_y = remnant_performance\n",
    "train_i = remnant_school_codes\n",
    "\n",
    "test_ff_X = experiment_demographics\n",
    "test_lstm_X = experiment_prior_performance\n",
    "test_y = experiment_performance\n",
    "test_i = experiment_school_codes\n",
    "\n",
    "# Clear session so models don't pile up\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# Normalize the input data based on the training data distribution\n",
    "ff_scaler = StandardScaler().fit(train_ff_X)\n",
    "train_ff_X = np.nan_to_num(ff_scaler.transform(train_ff_X))\n",
    "test_ff_X = np.nan_to_num(ff_scaler.transform(test_ff_X))\n",
    "\n",
    "train_lstm_X_shape = train_lstm_X.shape\n",
    "train_stacked_lstm_X = train_lstm_X.reshape(-1, train_lstm_X_shape[-1])\n",
    "lstm_scaler = StandardScaler().fit(train_stacked_lstm_X)\n",
    "train_lstm_X = np.nan_to_num(lstm_scaler.transform(train_stacked_lstm_X)).reshape(train_lstm_X_shape)\n",
    "test_lstm_X_shape = test_lstm_X.shape\n",
    "test_stacked_lstm_X = test_lstm_X.reshape(-1, test_lstm_X_shape[-1])\n",
    "test_lstm_X = np.nan_to_num(lstm_scaler.transform(test_stacked_lstm_X)).reshape(test_lstm_X_shape)\n",
    "\n",
    "# Create the neural network\n",
    "ff_input_layer = Input(shape=train_ff_X[0].shape)\n",
    "lstm_input_layer = Input(shape=train_lstm_X[0].shape)\n",
    "combined_input_layer = RepeatVector(train_lstm_X.shape[1])(ff_input_layer)\n",
    "combined_input_layer = Concatenate()([combined_input_layer, lstm_input_layer])\n",
    "\n",
    "model = Bidirectional(LSTM(units=128, return_sequences=True, activation='tanh', dropout=0.5, recurrent_dropout=0.5))(combined_input_layer)\n",
    "model = Bidirectional(LSTM(units=64, return_sequences=False, activation='tanh', dropout=0.5, recurrent_dropout=0.5))(model)\n",
    "output_layer = Dense(units=1, activation='sigmoid')(model)\n",
    "\n",
    "model = Model([ff_input_layer, lstm_input_layer], output_layer)\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the neural network\n",
    "es = [EarlyStopping(monitor='val_loss', patience=10, min_delta=0, restore_best_weights=True)]\n",
    "model.fit(x=[train_ff_X, train_lstm_X], y=train_y, batch_size=16, epochs=1000, validation_split=0.25, callbacks=es, verbose=1)\n",
    "\n",
    "# Use the neural network to predict the held-out fold\n",
    "pred_y = model.predict([test_ff_X, test_lstm_X]).flatten()\n",
    "\n",
    "# Update predictions\n",
    "results = pd.DataFrame([test_y, pred_y], columns=test_i, index=['actual_performance', 'predicted_performance']).T\n",
    "results.to_csv('results/experiment_predictions.csv')\n",
    "print(f'MSE: {mean_squared_error(results.actual_performance, results.predicted_performance)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

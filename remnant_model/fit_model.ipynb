{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Input, RepeatVector, Dense, Bidirectional, LSTM, Concatenate\n",
    "\n",
    "# Hide GPU from visible devices\n",
    "tf.config.set_visible_devices([], 'GPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "521 37 37 447 521\n"
     ]
    }
   ],
   "source": [
    "# Get groups of schools\n",
    "\n",
    "matches = pd.read_csv('input_data/matches.csv', dtype=str)\n",
    "treatment_schools = matches[matches['trt'] == '1']['school_code'].tolist()\n",
    "control_schools = matches[(matches['trt'] != '1') & (~matches['pairmatch'].isna())]['school_code'].tolist()\n",
    "remnant_schools = matches[matches['pairmatch'].isna()]['school_code'].tolist()\n",
    "print(len(matches), len(treatment_schools), len(control_schools), len(remnant_schools), len(treatment_schools) + len(control_schools) + len(remnant_schools))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(447, 69) (447, 5, 51) (447,) (447,)\n",
      "(74, 69) (74, 5, 51) (74,) (74,)\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "\n",
    "mass_doe_data = pd.read_csv('input_data/mass_doe_data.csv', dtype=str).astype(str)\n",
    "mass_doe_data = mass_doe_data.set_index('school_code')\n",
    "float_columns = [c for c in mass_doe_data if c != 'prior_performance']\n",
    "mass_doe_data[float_columns] = mass_doe_data[float_columns].astype(float)\n",
    "mass_doe_data['prior_performance'] = mass_doe_data['prior_performance'].apply(lambda x: np.array(eval(x.replace('nan', 'np.nan'))))\n",
    "mass_doe_data = mass_doe_data.sort_values('school_code')\n",
    "\n",
    "performance_data = pd.read_csv('input_data/performance.csv', dtype=str).astype(str)\n",
    "performance_data = performance_data.set_index('school_code')\n",
    "performance_data = performance_data.astype(float)\n",
    "performance_data = performance_data.sort_values('school_code')\n",
    "\n",
    "# Remnant data\n",
    "\n",
    "remnant_mass_doe_data = mass_doe_data[mass_doe_data.index.isin(remnant_schools)]\n",
    "remnant_performance_data = performance_data[performance_data.index.isin(remnant_schools)]\n",
    "remnant_demographics = remnant_mass_doe_data.drop(columns=['prior_performance']).values\n",
    "remnant_prior_performance = np.array(remnant_mass_doe_data['prior_performance'].tolist())\n",
    "remnant_performance = remnant_performance_data['performance'].values\n",
    "remnant_school_codes = np.array(remnant_performance_data.index)\n",
    "print(remnant_demographics.shape, remnant_prior_performance.shape, remnant_performance.shape, remnant_school_codes.shape)\n",
    "\n",
    "# Experiment data\n",
    "\n",
    "experiment_mass_doe_data = mass_doe_data[mass_doe_data.index.isin(treatment_schools + control_schools)]\n",
    "experiment_performance_data = performance_data[performance_data.index.isin(treatment_schools + control_schools)]\n",
    "experiment_demographics = experiment_mass_doe_data.drop(columns=['prior_performance']).values\n",
    "experiment_prior_performance = np.array(experiment_mass_doe_data['prior_performance'].tolist())\n",
    "experiment_performance = experiment_performance_data['performance'].values\n",
    "experiment_school_codes = np.array(experiment_performance_data.index)\n",
    "print(experiment_demographics.shape, experiment_prior_performance.shape, experiment_performance.shape, experiment_school_codes.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "19/19 [==============================] - 8s 54ms/step - loss: 3140.4812 - val_loss: 3510.4695\n",
      "Epoch 2/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 2353.3032 - val_loss: 2368.8926\n",
      "Epoch 3/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 1604.2129 - val_loss: 1911.2860\n",
      "Epoch 4/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 1356.5016 - val_loss: 1672.1255\n",
      "Epoch 5/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 1188.3777 - val_loss: 1497.7906\n",
      "Epoch 6/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 1053.1251 - val_loss: 1367.7495\n",
      "Epoch 7/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 935.2252 - val_loss: 1293.0848\n",
      "Epoch 8/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 835.0516 - val_loss: 1191.9227\n",
      "Epoch 9/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 753.3831 - val_loss: 1107.7362\n",
      "Epoch 10/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 685.3735 - val_loss: 1009.0009\n",
      "Epoch 11/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 625.3464 - val_loss: 941.2010\n",
      "Epoch 12/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 570.6092 - val_loss: 885.7700\n",
      "Epoch 13/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 509.5959 - val_loss: 841.2468\n",
      "Epoch 14/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 458.9171 - val_loss: 754.1014\n",
      "Epoch 15/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 416.0172 - val_loss: 700.7919\n",
      "Epoch 16/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 373.0745 - val_loss: 662.0581\n",
      "Epoch 17/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 339.4342 - val_loss: 629.7378\n",
      "Epoch 18/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 310.1021 - val_loss: 547.9872\n",
      "Epoch 19/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 284.4551 - val_loss: 558.1984\n",
      "Epoch 20/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 259.2155 - val_loss: 510.8599\n",
      "Epoch 21/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 232.1127 - val_loss: 459.7431\n",
      "Epoch 22/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 216.4006 - val_loss: 438.6154\n",
      "Epoch 23/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 201.7675 - val_loss: 425.9863\n",
      "Epoch 24/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 185.1694 - val_loss: 426.1139\n",
      "Epoch 25/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 168.8516 - val_loss: 408.1982\n",
      "Epoch 26/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 156.6914 - val_loss: 387.8196\n",
      "Epoch 27/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 144.7519 - val_loss: 368.1922\n",
      "Epoch 28/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 132.2471 - val_loss: 350.1823\n",
      "Epoch 29/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 127.6311 - val_loss: 352.3202\n",
      "Epoch 30/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 115.1864 - val_loss: 380.6730\n",
      "Epoch 31/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 107.6127 - val_loss: 330.1753\n",
      "Epoch 32/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 104.1772 - val_loss: 361.3434\n",
      "Epoch 33/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 93.8434 - val_loss: 397.8984\n",
      "Epoch 34/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 89.5663 - val_loss: 374.2685\n",
      "Epoch 35/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 80.1153 - val_loss: 352.1758\n",
      "Epoch 36/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 75.7131 - val_loss: 343.1962\n",
      "Epoch 37/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 73.4759 - val_loss: 354.2022\n",
      "Epoch 38/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 66.2741 - val_loss: 362.0917\n",
      "Epoch 39/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 62.1688 - val_loss: 374.1353\n",
      "Epoch 40/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 59.8554 - val_loss: 402.5470\n",
      "Epoch 41/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 59.9079 - val_loss: 355.0135\n",
      "Epoch 1/1000\n",
      "19/19 [==============================] - 7s 52ms/step - loss: 3135.3533 - val_loss: 3659.7886\n",
      "Epoch 2/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 2411.6597 - val_loss: 2641.0916\n",
      "Epoch 3/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 1722.3528 - val_loss: 2190.4553\n",
      "Epoch 4/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 1465.9408 - val_loss: 1941.4950\n",
      "Epoch 5/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 1285.5547 - val_loss: 1757.5967\n",
      "Epoch 6/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 1132.3358 - val_loss: 1639.9052\n",
      "Epoch 7/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 1011.8453 - val_loss: 1500.7712\n",
      "Epoch 8/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 905.5715 - val_loss: 1375.1965\n",
      "Epoch 9/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 819.0559 - val_loss: 1292.0786\n",
      "Epoch 10/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 742.1592 - val_loss: 1248.0715\n",
      "Epoch 11/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 678.5635 - val_loss: 1181.5410\n",
      "Epoch 12/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 622.9693 - val_loss: 1092.2620\n",
      "Epoch 13/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 573.9404 - val_loss: 984.2361\n",
      "Epoch 14/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 517.0482 - val_loss: 927.0663\n",
      "Epoch 15/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 471.7145 - val_loss: 787.2505\n",
      "Epoch 16/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 424.4070 - val_loss: 737.9005\n",
      "Epoch 17/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 380.9998 - val_loss: 710.0240\n",
      "Epoch 18/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 344.0540 - val_loss: 671.2963\n",
      "Epoch 19/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 313.5612 - val_loss: 621.7910\n",
      "Epoch 20/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 289.3386 - val_loss: 584.5337\n",
      "Epoch 21/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 263.6832 - val_loss: 531.9749\n",
      "Epoch 22/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 237.3631 - val_loss: 495.7406\n",
      "Epoch 23/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 220.3140 - val_loss: 492.1836\n",
      "Epoch 24/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 200.9734 - val_loss: 459.7086\n",
      "Epoch 25/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 187.7572 - val_loss: 460.1142\n",
      "Epoch 26/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 170.8309 - val_loss: 386.6841\n",
      "Epoch 27/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 159.5351 - val_loss: 391.2979\n",
      "Epoch 28/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 145.6236 - val_loss: 414.2679\n",
      "Epoch 29/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 140.2580 - val_loss: 389.0949\n",
      "Epoch 30/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 126.7377 - val_loss: 406.3769\n",
      "Epoch 31/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 120.2052 - val_loss: 380.6620\n",
      "Epoch 32/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 111.5054 - val_loss: 362.5115\n",
      "Epoch 33/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 109.2084 - val_loss: 361.2137\n",
      "Epoch 34/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 97.4808 - val_loss: 366.0927\n",
      "Epoch 35/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 95.2563 - val_loss: 361.7483\n",
      "Epoch 36/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 87.3445 - val_loss: 354.4680\n",
      "Epoch 37/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 82.1415 - val_loss: 369.3784\n",
      "Epoch 38/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 77.9393 - val_loss: 356.9720\n",
      "Epoch 39/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 73.0515 - val_loss: 322.5722\n",
      "Epoch 40/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 69.1957 - val_loss: 319.0480\n",
      "Epoch 41/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 65.3357 - val_loss: 365.7828\n",
      "Epoch 42/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 60.3818 - val_loss: 326.6870\n",
      "Epoch 43/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 56.3621 - val_loss: 341.1475\n",
      "Epoch 44/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 53.1456 - val_loss: 341.2791\n",
      "Epoch 45/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 51.9574 - val_loss: 325.6426\n",
      "Epoch 46/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 48.2120 - val_loss: 348.3708\n",
      "Epoch 47/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 47.0826 - val_loss: 328.7756\n",
      "Epoch 48/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 44.7785 - val_loss: 327.5330\n",
      "Epoch 49/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 42.7750 - val_loss: 346.3664\n",
      "Epoch 50/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 39.8901 - val_loss: 330.7592\n",
      "Epoch 1/1000\n",
      "19/19 [==============================] - 7s 51ms/step - loss: 3124.5134 - val_loss: 3552.5571\n",
      "Epoch 2/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 2339.1338 - val_loss: 2461.6382\n",
      "Epoch 3/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 1621.9788 - val_loss: 2035.9293\n",
      "Epoch 4/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 1370.8473 - val_loss: 1822.4199\n",
      "Epoch 5/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 1200.2402 - val_loss: 1673.0370\n",
      "Epoch 6/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 1058.4143 - val_loss: 1516.8704\n",
      "Epoch 7/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 945.1631 - val_loss: 1372.1390\n",
      "Epoch 8/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 847.9339 - val_loss: 1259.5211\n",
      "Epoch 9/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 765.7540 - val_loss: 1191.6404\n",
      "Epoch 10/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 693.1873 - val_loss: 1148.2516\n",
      "Epoch 11/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 630.0383 - val_loss: 1001.7766\n",
      "Epoch 12/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 573.2255 - val_loss: 915.5494\n",
      "Epoch 13/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 517.1695 - val_loss: 860.4596\n",
      "Epoch 14/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 467.2201 - val_loss: 828.7292\n",
      "Epoch 15/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 422.8964 - val_loss: 750.2004\n",
      "Epoch 16/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 387.6096 - val_loss: 680.5469\n",
      "Epoch 17/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 352.8336 - val_loss: 660.5775\n",
      "Epoch 18/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 320.9681 - val_loss: 638.9670\n",
      "Epoch 19/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 293.5989 - val_loss: 709.3811\n",
      "Epoch 20/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 263.2290 - val_loss: 623.2047\n",
      "Epoch 21/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 240.1521 - val_loss: 574.0345\n",
      "Epoch 22/1000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 219.2323 - val_loss: 514.4021\n",
      "Epoch 23/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 203.9979 - val_loss: 470.4377\n",
      "Epoch 24/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 185.7330 - val_loss: 463.3326\n",
      "Epoch 25/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 171.5681 - val_loss: 486.3041\n",
      "Epoch 26/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 162.8930 - val_loss: 428.7607\n",
      "Epoch 27/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 146.2562 - val_loss: 392.8732\n",
      "Epoch 28/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 137.3167 - val_loss: 458.6216\n",
      "Epoch 29/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 131.0784 - val_loss: 419.3626\n",
      "Epoch 30/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 119.4172 - val_loss: 415.9892\n",
      "Epoch 31/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 114.9268 - val_loss: 395.0436\n",
      "Epoch 32/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 106.9283 - val_loss: 392.0934\n",
      "Epoch 33/1000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 97.9066 - val_loss: 415.2056\n",
      "Epoch 34/1000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 95.3158 - val_loss: 340.8873\n",
      "Epoch 35/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 83.2264 - val_loss: 291.9058\n",
      "Epoch 36/1000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 85.9528 - val_loss: 327.0652\n",
      "Epoch 37/1000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 78.4321 - val_loss: 302.1038\n",
      "Epoch 38/1000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 72.1150 - val_loss: 346.7827\n",
      "Epoch 39/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 65.9471 - val_loss: 320.8221\n",
      "Epoch 40/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 63.7378 - val_loss: 402.1936\n",
      "Epoch 41/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 63.6618 - val_loss: 326.2442\n",
      "Epoch 42/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 57.3773 - val_loss: 378.1991\n",
      "Epoch 43/1000\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 57.1815 - val_loss: 318.4650\n",
      "Epoch 44/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 51.9023 - val_loss: 324.7057\n",
      "Epoch 45/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 45.7966 - val_loss: 325.7176\n",
      "Epoch 1/1000\n",
      "19/19 [==============================] - 7s 98ms/step - loss: 3170.0859 - val_loss: 3611.2693\n",
      "Epoch 2/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 2367.4158 - val_loss: 2570.6582\n",
      "Epoch 3/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 1686.5729 - val_loss: 2127.9614\n",
      "Epoch 4/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 1429.9767 - val_loss: 1923.8738\n",
      "Epoch 5/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 1257.4056 - val_loss: 1741.1088\n",
      "Epoch 6/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 1113.2467 - val_loss: 1584.0563\n",
      "Epoch 7/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 994.8122 - val_loss: 1505.8387\n",
      "Epoch 8/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 894.7540 - val_loss: 1342.4409\n",
      "Epoch 9/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 808.1541 - val_loss: 1208.4597\n",
      "Epoch 10/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 732.7133 - val_loss: 1128.1722\n",
      "Epoch 11/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 672.2678 - val_loss: 1096.8595\n",
      "Epoch 12/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 612.6484 - val_loss: 1059.2833\n",
      "Epoch 13/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 554.6045 - val_loss: 965.2924\n",
      "Epoch 14/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 507.9086 - val_loss: 927.1845\n",
      "Epoch 15/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 460.9207 - val_loss: 856.8246\n",
      "Epoch 16/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 414.7055 - val_loss: 793.3603\n",
      "Epoch 17/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 380.3433 - val_loss: 806.9415\n",
      "Epoch 18/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 345.4908 - val_loss: 754.2407\n",
      "Epoch 19/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 314.2507 - val_loss: 721.8690\n",
      "Epoch 20/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 286.2774 - val_loss: 697.5213\n",
      "Epoch 21/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 261.6703 - val_loss: 611.7351\n",
      "Epoch 22/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 246.4672 - val_loss: 584.6200\n",
      "Epoch 23/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 219.4121 - val_loss: 576.5263\n",
      "Epoch 24/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 198.7990 - val_loss: 574.8870\n",
      "Epoch 25/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 180.8480 - val_loss: 541.4635\n",
      "Epoch 26/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 165.9924 - val_loss: 519.6740\n",
      "Epoch 27/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 157.3859 - val_loss: 500.1882\n",
      "Epoch 28/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 143.2686 - val_loss: 501.4386\n",
      "Epoch 29/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 134.0509 - val_loss: 484.2466\n",
      "Epoch 30/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 123.8421 - val_loss: 460.4909\n",
      "Epoch 31/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 115.5262 - val_loss: 480.8343\n",
      "Epoch 32/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 106.2057 - val_loss: 460.7661\n",
      "Epoch 33/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 98.5794 - val_loss: 449.9733\n",
      "Epoch 34/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 94.7837 - val_loss: 456.2979\n",
      "Epoch 35/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 86.9386 - val_loss: 446.4174\n",
      "Epoch 36/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 80.7498 - val_loss: 482.8773\n",
      "Epoch 37/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 81.0121 - val_loss: 458.5760\n",
      "Epoch 38/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 72.9143 - val_loss: 451.4545\n",
      "Epoch 39/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 67.7564 - val_loss: 417.1606\n",
      "Epoch 40/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 63.6535 - val_loss: 421.4254\n",
      "Epoch 41/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 60.1608 - val_loss: 448.5508\n",
      "Epoch 42/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 58.7713 - val_loss: 438.4866\n",
      "Epoch 43/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 54.8113 - val_loss: 463.2600\n",
      "Epoch 44/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 55.0301 - val_loss: 480.0027\n",
      "Epoch 45/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 50.3558 - val_loss: 449.8228\n",
      "Epoch 46/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 46.7050 - val_loss: 473.3875\n",
      "Epoch 47/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 45.8638 - val_loss: 452.1120\n",
      "Epoch 48/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 44.5718 - val_loss: 475.3444\n",
      "Epoch 49/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 41.0983 - val_loss: 460.4839\n",
      "Epoch 1/1000\n",
      "19/19 [==============================] - 7s 54ms/step - loss: 3111.8088 - val_loss: 3661.1912\n",
      "Epoch 2/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 2321.7744 - val_loss: 2544.7141\n",
      "Epoch 3/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 1613.8091 - val_loss: 2111.5264\n",
      "Epoch 4/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 1366.5448 - val_loss: 1879.8038\n",
      "Epoch 5/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 1196.6980 - val_loss: 1716.9092\n",
      "Epoch 6/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 1053.0520 - val_loss: 1554.4771\n",
      "Epoch 7/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 937.3713 - val_loss: 1421.1350\n",
      "Epoch 8/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 849.6226 - val_loss: 1277.7546\n",
      "Epoch 9/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 758.9356 - val_loss: 1167.5629\n",
      "Epoch 10/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 689.2875 - val_loss: 1097.1910\n",
      "Epoch 11/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 631.9437 - val_loss: 1033.9465\n",
      "Epoch 12/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 580.3198 - val_loss: 976.0936\n",
      "Epoch 13/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 531.1862 - val_loss: 887.2386\n",
      "Epoch 14/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 478.6209 - val_loss: 878.3102\n",
      "Epoch 15/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 431.9991 - val_loss: 828.1267\n",
      "Epoch 16/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 392.5962 - val_loss: 714.8237\n",
      "Epoch 17/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 353.2939 - val_loss: 678.0067\n",
      "Epoch 18/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 322.7744 - val_loss: 646.8003\n",
      "Epoch 19/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 293.7279 - val_loss: 598.4490\n",
      "Epoch 20/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 269.9091 - val_loss: 573.6515\n",
      "Epoch 21/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 246.8813 - val_loss: 526.9847\n",
      "Epoch 22/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 227.7913 - val_loss: 508.4251\n",
      "Epoch 23/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 205.8995 - val_loss: 464.3467\n",
      "Epoch 24/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 194.7820 - val_loss: 503.7880\n",
      "Epoch 25/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 179.5769 - val_loss: 488.8995\n",
      "Epoch 26/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 163.3400 - val_loss: 433.4680\n",
      "Epoch 27/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 153.3195 - val_loss: 513.8922\n",
      "Epoch 28/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 141.9349 - val_loss: 349.1451\n",
      "Epoch 29/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 132.1286 - val_loss: 341.3156\n",
      "Epoch 30/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 121.9690 - val_loss: 396.3564\n",
      "Epoch 31/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 113.7615 - val_loss: 343.4886\n",
      "Epoch 32/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 108.1105 - val_loss: 338.0750\n",
      "Epoch 33/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 95.6494 - val_loss: 334.2884\n",
      "Epoch 34/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 91.2848 - val_loss: 304.9826\n",
      "Epoch 35/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 87.1681 - val_loss: 283.4790\n",
      "Epoch 36/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 83.6834 - val_loss: 308.0498\n",
      "Epoch 37/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 78.1166 - val_loss: 302.2219\n",
      "Epoch 38/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 71.4079 - val_loss: 289.4588\n",
      "Epoch 39/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 67.3430 - val_loss: 312.4974\n",
      "Epoch 40/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 63.5867 - val_loss: 295.2536\n",
      "Epoch 41/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 58.8224 - val_loss: 279.1030\n",
      "Epoch 42/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 56.5927 - val_loss: 294.1583\n",
      "Epoch 43/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 55.2981 - val_loss: 294.1775\n",
      "Epoch 44/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 50.7377 - val_loss: 321.7128\n",
      "Epoch 45/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 46.2698 - val_loss: 298.5247\n",
      "Epoch 46/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 46.4468 - val_loss: 360.2110\n",
      "Epoch 47/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 45.8554 - val_loss: 318.2564\n",
      "Epoch 48/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 43.0286 - val_loss: 305.9662\n",
      "Epoch 49/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 39.5698 - val_loss: 316.5819\n",
      "Epoch 50/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 39.1384 - val_loss: 307.7401\n",
      "Epoch 51/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 37.0206 - val_loss: 318.1124\n",
      "Epoch 1/1000\n",
      "19/19 [==============================] - 8s 54ms/step - loss: 3099.1663 - val_loss: 3595.0662\n",
      "Epoch 2/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 2351.8428 - val_loss: 2582.5957\n",
      "Epoch 3/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 1647.5598 - val_loss: 2088.1296\n",
      "Epoch 4/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 1391.7911 - val_loss: 1853.1858\n",
      "Epoch 5/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 1223.5736 - val_loss: 1686.1061\n",
      "Epoch 6/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 1073.7639 - val_loss: 1629.3057\n",
      "Epoch 7/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 953.0621 - val_loss: 1507.0114\n",
      "Epoch 8/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 855.3343 - val_loss: 1390.1051\n",
      "Epoch 9/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 769.9461 - val_loss: 1282.4949\n",
      "Epoch 10/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 697.6447 - val_loss: 1191.9335\n",
      "Epoch 11/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 637.3197 - val_loss: 1138.6890\n",
      "Epoch 12/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 576.7734 - val_loss: 1071.9165\n",
      "Epoch 13/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 536.2116 - val_loss: 932.3079\n",
      "Epoch 14/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 478.5722 - val_loss: 862.3420\n",
      "Epoch 15/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 429.3732 - val_loss: 876.3133\n",
      "Epoch 16/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 389.4633 - val_loss: 846.3469\n",
      "Epoch 17/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 355.1899 - val_loss: 781.4458\n",
      "Epoch 18/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 322.5393 - val_loss: 710.1439\n",
      "Epoch 19/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 292.3286 - val_loss: 698.1412\n",
      "Epoch 20/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 267.3951 - val_loss: 653.9002\n",
      "Epoch 21/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 248.7278 - val_loss: 612.1657\n",
      "Epoch 22/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 223.0056 - val_loss: 572.4813\n",
      "Epoch 23/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 207.3226 - val_loss: 562.9233\n",
      "Epoch 24/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 188.0941 - val_loss: 540.4095\n",
      "Epoch 25/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 174.7143 - val_loss: 514.3250\n",
      "Epoch 26/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 161.1661 - val_loss: 514.8307\n",
      "Epoch 27/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 148.4551 - val_loss: 486.5520\n",
      "Epoch 28/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 138.9986 - val_loss: 454.8454\n",
      "Epoch 29/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 129.9382 - val_loss: 437.8752\n",
      "Epoch 30/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 120.1710 - val_loss: 421.1562\n",
      "Epoch 31/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 112.5264 - val_loss: 431.8521\n",
      "Epoch 32/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 104.9418 - val_loss: 418.3194\n",
      "Epoch 33/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 96.5609 - val_loss: 438.7545\n",
      "Epoch 34/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 90.1436 - val_loss: 418.8941\n",
      "Epoch 35/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 86.3833 - val_loss: 404.7063\n",
      "Epoch 36/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 81.2881 - val_loss: 378.2765\n",
      "Epoch 37/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 81.0084 - val_loss: 406.0033\n",
      "Epoch 38/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 75.5174 - val_loss: 398.4534\n",
      "Epoch 39/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 71.4036 - val_loss: 416.7369\n",
      "Epoch 40/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 67.6164 - val_loss: 419.8938\n",
      "Epoch 41/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 64.3702 - val_loss: 440.0553\n",
      "Epoch 42/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 60.1214 - val_loss: 422.0542\n",
      "Epoch 43/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 57.2055 - val_loss: 393.5961\n",
      "Epoch 44/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 55.3385 - val_loss: 368.5081\n",
      "Epoch 45/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 52.1732 - val_loss: 405.2373\n",
      "Epoch 46/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 50.2330 - val_loss: 424.6210\n",
      "Epoch 47/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 47.8648 - val_loss: 402.2009\n",
      "Epoch 48/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 46.2646 - val_loss: 417.4305\n",
      "Epoch 49/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 44.0733 - val_loss: 448.5624\n",
      "Epoch 50/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 42.7751 - val_loss: 432.1328\n",
      "Epoch 51/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 39.0693 - val_loss: 410.0550\n",
      "Epoch 52/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 37.3745 - val_loss: 438.4447\n",
      "Epoch 53/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 39.6828 - val_loss: 472.9677\n",
      "Epoch 54/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 35.8254 - val_loss: 440.4296\n",
      "Epoch 1/1000\n",
      "19/19 [==============================] - 8s 59ms/step - loss: 3168.3923 - val_loss: 3649.7246\n",
      "Epoch 2/1000\n",
      "19/19 [==============================] - 0s 22ms/step - loss: 2419.0703 - val_loss: 2585.9175\n",
      "Epoch 3/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 1729.1639 - val_loss: 2142.4631\n",
      "Epoch 4/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 1470.0458 - val_loss: 1911.8438\n",
      "Epoch 5/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 1284.7245 - val_loss: 1736.8917\n",
      "Epoch 6/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 1137.3348 - val_loss: 1573.6813\n",
      "Epoch 7/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 1014.3833 - val_loss: 1428.7974\n",
      "Epoch 8/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 910.3123 - val_loss: 1303.3181\n",
      "Epoch 9/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 823.1155 - val_loss: 1202.3726\n",
      "Epoch 10/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 744.2728 - val_loss: 1129.5697\n",
      "Epoch 11/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 678.2151 - val_loss: 992.1702\n",
      "Epoch 12/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 620.3157 - val_loss: 909.9557\n",
      "Epoch 13/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 565.6641 - val_loss: 844.2946\n",
      "Epoch 14/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 505.9836 - val_loss: 805.8160\n",
      "Epoch 15/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 460.5424 - val_loss: 797.0623\n",
      "Epoch 16/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 414.8538 - val_loss: 772.2231\n",
      "Epoch 17/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 378.1649 - val_loss: 698.1968\n",
      "Epoch 18/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 340.9796 - val_loss: 698.7216\n",
      "Epoch 19/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 320.7096 - val_loss: 601.2754\n",
      "Epoch 20/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 285.0797 - val_loss: 556.6948\n",
      "Epoch 21/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 262.4904 - val_loss: 504.4540\n",
      "Epoch 22/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 239.7976 - val_loss: 497.8781\n",
      "Epoch 23/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 219.9731 - val_loss: 478.1047\n",
      "Epoch 24/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 200.4019 - val_loss: 419.4490\n",
      "Epoch 25/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 188.4167 - val_loss: 386.8774\n",
      "Epoch 26/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 174.7039 - val_loss: 405.7672\n",
      "Epoch 27/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 162.1195 - val_loss: 386.9099\n",
      "Epoch 28/1000\n",
      "19/19 [==============================] - 0s 22ms/step - loss: 148.7398 - val_loss: 382.1046\n",
      "Epoch 29/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 140.6662 - val_loss: 363.2860\n",
      "Epoch 30/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 132.7026 - val_loss: 334.1690\n",
      "Epoch 31/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 121.9460 - val_loss: 342.2903\n",
      "Epoch 32/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 115.3513 - val_loss: 313.1400\n",
      "Epoch 33/1000\n",
      "19/19 [==============================] - 0s 22ms/step - loss: 103.6480 - val_loss: 320.4725\n",
      "Epoch 34/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 96.6117 - val_loss: 370.0127\n",
      "Epoch 35/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 93.0364 - val_loss: 332.9885\n",
      "Epoch 36/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 85.8921 - val_loss: 339.6009\n",
      "Epoch 37/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 82.0200 - val_loss: 335.2891\n",
      "Epoch 38/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 78.1701 - val_loss: 332.2936\n",
      "Epoch 39/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 74.4549 - val_loss: 358.5109\n",
      "Epoch 40/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 69.3471 - val_loss: 370.0067\n",
      "Epoch 41/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 67.2625 - val_loss: 337.1425\n",
      "Epoch 42/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 60.8487 - val_loss: 337.2810\n",
      "Epoch 1/1000\n",
      "19/19 [==============================] - 8s 53ms/step - loss: 3158.6953 - val_loss: 3465.0728\n",
      "Epoch 2/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 2387.3018 - val_loss: 2424.0703\n",
      "Epoch 3/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 1680.7885 - val_loss: 1993.2391\n",
      "Epoch 4/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 1420.6189 - val_loss: 1779.1787\n",
      "Epoch 5/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 1244.9324 - val_loss: 1635.0045\n",
      "Epoch 6/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 1101.1559 - val_loss: 1487.8126\n",
      "Epoch 7/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 980.3750 - val_loss: 1336.9003\n",
      "Epoch 8/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 881.6027 - val_loss: 1234.1857\n",
      "Epoch 9/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 798.7291 - val_loss: 1149.5844\n",
      "Epoch 10/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 724.4291 - val_loss: 1060.5786\n",
      "Epoch 11/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 668.5242 - val_loss: 991.5668\n",
      "Epoch 12/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 615.8577 - val_loss: 945.1137\n",
      "Epoch 13/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 565.9301 - val_loss: 922.0788\n",
      "Epoch 14/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 514.9553 - val_loss: 851.7948\n",
      "Epoch 15/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 459.0158 - val_loss: 779.8484\n",
      "Epoch 16/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 408.7947 - val_loss: 730.1282\n",
      "Epoch 17/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 370.3229 - val_loss: 670.9632\n",
      "Epoch 18/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 337.8998 - val_loss: 646.2905\n",
      "Epoch 19/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 307.9450 - val_loss: 639.1224\n",
      "Epoch 20/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 280.0086 - val_loss: 604.5352\n",
      "Epoch 21/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 256.3581 - val_loss: 567.8123\n",
      "Epoch 22/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 232.3218 - val_loss: 513.7187\n",
      "Epoch 23/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 213.2201 - val_loss: 452.9222\n",
      "Epoch 24/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 194.3627 - val_loss: 433.4773\n",
      "Epoch 25/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 177.8785 - val_loss: 437.1109\n",
      "Epoch 26/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 161.0509 - val_loss: 402.7688\n",
      "Epoch 27/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 149.8819 - val_loss: 331.9751\n",
      "Epoch 28/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 140.3932 - val_loss: 329.1216\n",
      "Epoch 29/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 128.2195 - val_loss: 355.1148\n",
      "Epoch 30/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 118.4472 - val_loss: 357.6014\n",
      "Epoch 31/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 111.2849 - val_loss: 342.2743\n",
      "Epoch 32/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 101.6382 - val_loss: 320.7438\n",
      "Epoch 33/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 94.0845 - val_loss: 335.2420\n",
      "Epoch 34/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 89.6820 - val_loss: 322.0886\n",
      "Epoch 35/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 82.7274 - val_loss: 325.7785\n",
      "Epoch 36/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 77.7907 - val_loss: 382.5482\n",
      "Epoch 37/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 75.6302 - val_loss: 377.8728\n",
      "Epoch 38/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 69.7720 - val_loss: 342.7645\n",
      "Epoch 39/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 64.1660 - val_loss: 391.7329\n",
      "Epoch 40/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 59.0422 - val_loss: 338.3864\n",
      "Epoch 41/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 58.0564 - val_loss: 323.4588\n",
      "Epoch 42/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 50.2033 - val_loss: 343.8108\n",
      "Epoch 1/1000\n",
      "19/19 [==============================] - 6s 49ms/step - loss: 3105.6177 - val_loss: 3457.9250\n",
      "Epoch 2/1000\n",
      "19/19 [==============================] - 1s 59ms/step - loss: 2328.3313 - val_loss: 2430.7314\n",
      "Epoch 3/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 1595.9774 - val_loss: 1962.9269\n",
      "Epoch 4/1000\n",
      "19/19 [==============================] - 0s 22ms/step - loss: 1336.5319 - val_loss: 1759.4346\n",
      "Epoch 5/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 1172.0522 - val_loss: 1642.9738\n",
      "Epoch 6/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 1035.7830 - val_loss: 1532.6431\n",
      "Epoch 7/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 919.4974 - val_loss: 1447.1429\n",
      "Epoch 8/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 826.5616 - val_loss: 1289.7677\n",
      "Epoch 9/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 745.8256 - val_loss: 1132.4038\n",
      "Epoch 10/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 674.6306 - val_loss: 1083.8448\n",
      "Epoch 11/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 610.5149 - val_loss: 1014.0280\n",
      "Epoch 12/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 545.3077 - val_loss: 962.8630\n",
      "Epoch 13/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 494.1765 - val_loss: 952.0530\n",
      "Epoch 14/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 447.4184 - val_loss: 870.5887\n",
      "Epoch 15/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 403.5136 - val_loss: 792.6774\n",
      "Epoch 16/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 364.2930 - val_loss: 740.0125\n",
      "Epoch 17/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 334.6902 - val_loss: 674.3883\n",
      "Epoch 18/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 310.7422 - val_loss: 677.4932\n",
      "Epoch 19/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 276.9162 - val_loss: 603.8969\n",
      "Epoch 20/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 253.3339 - val_loss: 561.7905\n",
      "Epoch 21/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 232.6258 - val_loss: 512.6505\n",
      "Epoch 22/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 213.2387 - val_loss: 544.3729\n",
      "Epoch 23/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 200.1101 - val_loss: 530.0730\n",
      "Epoch 24/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 191.6042 - val_loss: 549.8350\n",
      "Epoch 25/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 170.3276 - val_loss: 515.2002\n",
      "Epoch 26/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 154.3396 - val_loss: 425.5266\n",
      "Epoch 27/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 144.4044 - val_loss: 419.6414\n",
      "Epoch 28/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 132.7693 - val_loss: 457.2866\n",
      "Epoch 29/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 126.0647 - val_loss: 417.2408\n",
      "Epoch 30/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 116.2857 - val_loss: 427.8012\n",
      "Epoch 31/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 107.5771 - val_loss: 433.7591\n",
      "Epoch 32/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 98.7269 - val_loss: 419.5185\n",
      "Epoch 33/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 91.4212 - val_loss: 445.1487\n",
      "Epoch 34/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 87.5035 - val_loss: 423.3766\n",
      "Epoch 35/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 84.7887 - val_loss: 473.7731\n",
      "Epoch 36/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 80.2895 - val_loss: 436.2694\n",
      "Epoch 37/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 75.0481 - val_loss: 461.1198\n",
      "Epoch 38/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 70.3577 - val_loss: 499.9278\n",
      "Epoch 39/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 64.6776 - val_loss: 447.6357\n",
      "Epoch 1/1000\n",
      "19/19 [==============================] - 8s 56ms/step - loss: 3176.0234 - val_loss: 3593.1460\n",
      "Epoch 2/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 2389.9885 - val_loss: 2507.8342\n",
      "Epoch 3/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 1704.8704 - val_loss: 2089.4907\n",
      "Epoch 4/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 1456.5820 - val_loss: 1864.6572\n",
      "Epoch 5/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 1273.7263 - val_loss: 1700.6401\n",
      "Epoch 6/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 1128.1940 - val_loss: 1547.6719\n",
      "Epoch 7/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 1006.6722 - val_loss: 1409.6128\n",
      "Epoch 8/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 901.6693 - val_loss: 1291.3640\n",
      "Epoch 9/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 816.1945 - val_loss: 1187.3126\n",
      "Epoch 10/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 738.9971 - val_loss: 1094.7548\n",
      "Epoch 11/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 674.3643 - val_loss: 1018.8273\n",
      "Epoch 12/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 611.7545 - val_loss: 937.8571\n",
      "Epoch 13/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 550.7314 - val_loss: 876.8369\n",
      "Epoch 14/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 495.4735 - val_loss: 822.3544\n",
      "Epoch 15/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 452.1823 - val_loss: 757.4523\n",
      "Epoch 16/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 406.9923 - val_loss: 694.7936\n",
      "Epoch 17/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 368.1516 - val_loss: 676.7271\n",
      "Epoch 18/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 332.9134 - val_loss: 640.8079\n",
      "Epoch 19/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 305.5314 - val_loss: 593.5039\n",
      "Epoch 20/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 276.4281 - val_loss: 587.1342\n",
      "Epoch 21/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 254.5907 - val_loss: 531.2731\n",
      "Epoch 22/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 232.1145 - val_loss: 537.9485\n",
      "Epoch 23/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 211.8111 - val_loss: 474.2613\n",
      "Epoch 24/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 193.5935 - val_loss: 424.1269\n",
      "Epoch 25/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 180.5379 - val_loss: 397.4908\n",
      "Epoch 26/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 162.4313 - val_loss: 382.5212\n",
      "Epoch 27/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 157.6346 - val_loss: 357.4619\n",
      "Epoch 28/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 142.0290 - val_loss: 343.6559\n",
      "Epoch 29/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 131.4391 - val_loss: 342.7493\n",
      "Epoch 30/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 122.1650 - val_loss: 328.9391\n",
      "Epoch 31/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 116.9727 - val_loss: 331.0980\n",
      "Epoch 32/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 110.2874 - val_loss: 322.6729\n",
      "Epoch 33/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 101.6257 - val_loss: 320.3337\n",
      "Epoch 34/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 94.9666 - val_loss: 317.9807\n",
      "Epoch 35/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 90.3883 - val_loss: 330.4044\n",
      "Epoch 36/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 82.3297 - val_loss: 325.7001\n",
      "Epoch 37/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 77.7121 - val_loss: 335.6266\n",
      "Epoch 38/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 74.8943 - val_loss: 336.4905\n",
      "Epoch 39/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 70.3272 - val_loss: 347.8130\n",
      "Epoch 40/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 64.7100 - val_loss: 328.9224\n",
      "Epoch 41/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 62.5897 - val_loss: 320.3679\n",
      "Epoch 42/1000\n",
      "19/19 [==============================] - 0s 22ms/step - loss: 59.4233 - val_loss: 314.7561\n",
      "Epoch 43/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 58.8869 - val_loss: 316.5022\n",
      "Epoch 44/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 52.8310 - val_loss: 328.5999\n",
      "Epoch 45/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 51.1956 - val_loss: 355.0799\n",
      "Epoch 46/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 49.3368 - val_loss: 343.6789\n",
      "Epoch 47/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 45.9559 - val_loss: 348.8675\n",
      "Epoch 48/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 42.1698 - val_loss: 334.2115\n",
      "Epoch 49/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 40.4755 - val_loss: 347.9179\n",
      "Epoch 50/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 40.9781 - val_loss: 342.5906\n",
      "Epoch 51/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 38.8265 - val_loss: 343.5504\n",
      "Epoch 52/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 36.1819 - val_loss: 345.1361\n",
      "MSE: 199.23285354558072\n"
     ]
    }
   ],
   "source": [
    "# Get model quality using k-fold on remnant\n",
    "\n",
    "ff_X = remnant_demographics\n",
    "lstm_X = remnant_prior_performance\n",
    "y = remnant_performance\n",
    "i = remnant_school_codes\n",
    "\n",
    "results = []\n",
    "for train_index, test_index in KFold(n_splits=10, shuffle=True).split(ff_X, y):\n",
    "\n",
    "    # Clear session so models don't pile up\n",
    "    keras.backend.clear_session()\n",
    "\n",
    "    # Split data into training and testing splits\n",
    "    train_ff_X, test_ff_X = ff_X[train_index], ff_X[test_index]\n",
    "    train_lstm_X, test_lstm_X = lstm_X[train_index], lstm_X[test_index]\n",
    "    train_y, test_y = y[train_index], y[test_index]\n",
    "    train_i, test_i = i[train_index], i[test_index]\n",
    "\n",
    "    # Normalize the input data based on the training data distribution\n",
    "    ff_scaler = StandardScaler().fit(train_ff_X)\n",
    "    train_ff_X = np.nan_to_num(ff_scaler.transform(train_ff_X))\n",
    "    test_ff_X = np.nan_to_num(ff_scaler.transform(test_ff_X))\n",
    "\n",
    "    train_lstm_X_shape = train_lstm_X.shape\n",
    "    train_stacked_lstm_X = train_lstm_X.reshape(-1, train_lstm_X_shape[-1])\n",
    "    lstm_scaler = StandardScaler().fit(train_stacked_lstm_X)\n",
    "    train_lstm_X = np.nan_to_num(lstm_scaler.transform(train_stacked_lstm_X)).reshape(train_lstm_X_shape)\n",
    "    test_lstm_X_shape = test_lstm_X.shape\n",
    "    test_stacked_lstm_X = test_lstm_X.reshape(-1, test_lstm_X_shape[-1])\n",
    "    test_lstm_X = np.nan_to_num(lstm_scaler.transform(test_stacked_lstm_X)).reshape(test_lstm_X_shape)\n",
    "\n",
    "    # Create the neural network\n",
    "    ff_input_layer = Input(shape=train_ff_X[0].shape)\n",
    "    lstm_input_layer = Input(shape=train_lstm_X[0].shape)\n",
    "    combined_input_layer = RepeatVector(train_lstm_X.shape[1])(ff_input_layer)\n",
    "    combined_input_layer = Concatenate()([combined_input_layer, lstm_input_layer])\n",
    "\n",
    "    model = Bidirectional(LSTM(units=128, return_sequences=True, activation='tanh', dropout=0.5, recurrent_dropout=0.5))(combined_input_layer)\n",
    "    model = Bidirectional(LSTM(units=64, return_sequences=False, activation='tanh', dropout=0.5, recurrent_dropout=0.5))(model)\n",
    "    output_layer = Dense(units=1, activation='linear')(model)\n",
    "\n",
    "    model = Model([ff_input_layer, lstm_input_layer], output_layer)\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    # Train the neural network\n",
    "    es = [EarlyStopping(monitor='val_loss', patience=10, min_delta=0, restore_best_weights=True)]\n",
    "    model.fit(x=[train_ff_X, train_lstm_X], y=train_y, batch_size=16, epochs=1000, validation_split=0.25, callbacks=es, verbose=1)\n",
    "\n",
    "    # Use the neural network to predict the held-out fold\n",
    "    pred_y = model.predict([test_ff_X, test_lstm_X]).flatten()\n",
    "\n",
    "    # Update predictions\n",
    "    results.append(pd.DataFrame([test_y, pred_y], columns=test_i, index=['actual_performance', 'predicted_performance']).T)\n",
    "\n",
    "results = pd.concat(results)\n",
    "results.to_csv('results/kfold_remnant_predictions.csv')\n",
    "print(f'MSE: {mean_squared_error(results.actual_performance, results.predicted_performance)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Mean Prediction MSE: 433.9361577972904\n",
    "\n",
    "(layers)     , dropout , batch size: MSE\n",
    "\n",
    "(64, 32)     , 0       , 32        : 261.0934134399656\n",
    "(32)         , 0       , 32        : 408.9117164445174\n",
    "(64, 32)     , 0.5     , 32        : 227.8827418178931\n",
    "(64, 64)     , 0.25    , 32        : 213.6578965631596\n",
    "(64, 64, 64) , 0.25    , 32        : 264.9091609712526\n",
    "(128, 64)    , 0.5     , 32        : 170.0072276619494\n",
    "(128, 64)    , 0.5     , 16        : 163.5255262041347 / 199.23285354558072***\n",
    "(128, 64)    , 0.5     , 8         : 183.8387565630688\n",
    "(256, 256)   , 0.5     , 16        : 163.1883336295512\n",
    "(128, 128)   , 0.5     , 16        : 172.0166126039364\n",
    "(256, 128)   , 0.5     , 16        : 177.0513539259982\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "21/21 [==============================] - 8s 50ms/step - loss: 3093.1406 - val_loss: 3505.5574\n",
      "Epoch 2/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 2243.9429 - val_loss: 2446.9783\n",
      "Epoch 3/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 1612.6228 - val_loss: 2048.4456\n",
      "Epoch 4/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 1377.0444 - val_loss: 1818.3348\n",
      "Epoch 5/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 1194.1477 - val_loss: 1705.1327\n",
      "Epoch 6/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 1044.8142 - val_loss: 1572.9720\n",
      "Epoch 7/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 922.5765 - val_loss: 1429.0734\n",
      "Epoch 8/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 822.8928 - val_loss: 1311.6455\n",
      "Epoch 9/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 739.4445 - val_loss: 1213.5487\n",
      "Epoch 10/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 666.3168 - val_loss: 1090.6622\n",
      "Epoch 11/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 602.6083 - val_loss: 1035.8710\n",
      "Epoch 12/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 538.6808 - val_loss: 931.2534\n",
      "Epoch 13/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 486.0420 - val_loss: 857.8110\n",
      "Epoch 14/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 434.0420 - val_loss: 843.7471\n",
      "Epoch 15/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 390.4152 - val_loss: 792.0374\n",
      "Epoch 16/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 349.2168 - val_loss: 755.4573\n",
      "Epoch 17/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 316.7230 - val_loss: 753.7331\n",
      "Epoch 18/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 286.6571 - val_loss: 620.5076\n",
      "Epoch 19/1000\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 258.7589 - val_loss: 592.6693\n",
      "Epoch 20/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 233.9746 - val_loss: 572.2278\n",
      "Epoch 21/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 215.3357 - val_loss: 511.1629\n",
      "Epoch 22/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 196.4931 - val_loss: 513.6128\n",
      "Epoch 23/1000\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 177.6215 - val_loss: 480.5354\n",
      "Epoch 24/1000\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 161.4706 - val_loss: 449.4392\n",
      "Epoch 25/1000\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 148.5167 - val_loss: 435.9600\n",
      "Epoch 26/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 142.1270 - val_loss: 409.8691\n",
      "Epoch 27/1000\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 129.8648 - val_loss: 416.3831\n",
      "Epoch 28/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 124.3430 - val_loss: 417.4563\n",
      "Epoch 29/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 115.8599 - val_loss: 403.0181\n",
      "Epoch 30/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 99.9397 - val_loss: 426.0617\n",
      "Epoch 31/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 96.5589 - val_loss: 392.7026\n",
      "Epoch 32/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 90.9213 - val_loss: 410.4089\n",
      "Epoch 33/1000\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 85.9271 - val_loss: 399.8692\n",
      "Epoch 34/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 76.8949 - val_loss: 415.9807\n",
      "Epoch 35/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 72.2696 - val_loss: 413.9168\n",
      "Epoch 36/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 71.4458 - val_loss: 419.3895\n",
      "Epoch 37/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 64.8310 - val_loss: 422.6818\n",
      "Epoch 38/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 60.4309 - val_loss: 357.0091\n",
      "Epoch 39/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 59.6574 - val_loss: 433.9367\n",
      "Epoch 40/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 53.4723 - val_loss: 434.6635\n",
      "Epoch 41/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 52.9380 - val_loss: 410.8906\n",
      "Epoch 42/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 46.8576 - val_loss: 435.1959\n",
      "Epoch 43/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 44.6630 - val_loss: 414.6152\n",
      "Epoch 44/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 41.1542 - val_loss: 455.9659\n",
      "Epoch 45/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 41.9411 - val_loss: 438.1388\n",
      "Epoch 46/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 41.2189 - val_loss: 430.6057\n",
      "Epoch 47/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 39.6940 - val_loss: 431.3824\n",
      "Epoch 48/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 36.3307 - val_loss: 420.0424\n",
      "MSE: 100.23964504026503\n"
     ]
    }
   ],
   "source": [
    "# Get predictions for experiment data\n",
    "\n",
    "train_ff_X = remnant_demographics\n",
    "train_lstm_X = remnant_prior_performance\n",
    "train_y = remnant_performance\n",
    "train_i = remnant_school_codes\n",
    "\n",
    "test_ff_X = experiment_demographics\n",
    "test_lstm_X = experiment_prior_performance\n",
    "test_y = experiment_performance\n",
    "test_i = experiment_school_codes\n",
    "\n",
    "# Clear session so models don't pile up\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# Normalize the input data based on the training data distribution\n",
    "ff_scaler = StandardScaler().fit(train_ff_X)\n",
    "train_ff_X = np.nan_to_num(ff_scaler.transform(train_ff_X))\n",
    "test_ff_X = np.nan_to_num(ff_scaler.transform(test_ff_X))\n",
    "\n",
    "train_lstm_X_shape = train_lstm_X.shape\n",
    "train_stacked_lstm_X = train_lstm_X.reshape(-1, train_lstm_X_shape[-1])\n",
    "lstm_scaler = StandardScaler().fit(train_stacked_lstm_X)\n",
    "train_lstm_X = np.nan_to_num(lstm_scaler.transform(train_stacked_lstm_X)).reshape(train_lstm_X_shape)\n",
    "test_lstm_X_shape = test_lstm_X.shape\n",
    "test_stacked_lstm_X = test_lstm_X.reshape(-1, test_lstm_X_shape[-1])\n",
    "test_lstm_X = np.nan_to_num(lstm_scaler.transform(test_stacked_lstm_X)).reshape(test_lstm_X_shape)\n",
    "\n",
    "# Create the neural network\n",
    "ff_input_layer = Input(shape=train_ff_X[0].shape)\n",
    "lstm_input_layer = Input(shape=train_lstm_X[0].shape)\n",
    "combined_input_layer = RepeatVector(train_lstm_X.shape[1])(ff_input_layer)\n",
    "combined_input_layer = Concatenate()([combined_input_layer, lstm_input_layer])\n",
    "\n",
    "model = Bidirectional(LSTM(units=128, return_sequences=True, activation='tanh', dropout=0.5, recurrent_dropout=0.5))(combined_input_layer)\n",
    "model = Bidirectional(LSTM(units=64, return_sequences=False, activation='tanh', dropout=0.5, recurrent_dropout=0.5))(model)\n",
    "output_layer = Dense(units=1, activation='linear')(model)\n",
    "\n",
    "model = Model([ff_input_layer, lstm_input_layer], output_layer)\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the neural network\n",
    "es = [EarlyStopping(monitor='val_loss', patience=10, min_delta=0, restore_best_weights=True)]\n",
    "model.fit(x=[train_ff_X, train_lstm_X], y=train_y, batch_size=16, epochs=1000, validation_split=0.25, callbacks=es, verbose=1)\n",
    "\n",
    "# Use the neural network to predict the held-out fold\n",
    "pred_y = model.predict([test_ff_X, test_lstm_X]).flatten()\n",
    "\n",
    "# Update predictions\n",
    "results = pd.DataFrame([test_y, pred_y], columns=test_i, index=['actual_performance', 'predicted_performance']).T\n",
    "results.to_csv('results/experiment_predictions.csv')\n",
    "print(f'MSE: {mean_squared_error(results.actual_performance, results.predicted_performance)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

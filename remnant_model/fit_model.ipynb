{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Input, RepeatVector, Dense, Bidirectional, LSTM, Concatenate\n",
    "\n",
    "# Hide GPU from visible devices\n",
    "tf.config.set_visible_devices([], 'GPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "521 37 37 447 521\n"
     ]
    }
   ],
   "source": [
    "# Get groups of schools\n",
    "\n",
    "matches = pd.read_csv('input_data/matches.csv', dtype=str)\n",
    "treatment_schools = matches[matches['trt'] == '1']['school_code'].tolist()\n",
    "control_schools = matches[(matches['trt'] != '1') & (~matches['pairmatch'].isna())]['school_code'].tolist()\n",
    "remnant_schools = matches[matches['pairmatch'].isna()]['school_code'].tolist()\n",
    "print(len(matches), len(treatment_schools), len(control_schools), len(remnant_schools), len(treatment_schools) + len(control_schools) + len(remnant_schools))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(447, 70) (447, 5, 51) (447,) (447,)\n",
      "(74, 70) (74, 5, 51) (74,) (74,)\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "\n",
    "mass_doe_data = pd.read_csv('input_data/mass_doe_data.csv', dtype=str).astype(str)\n",
    "mass_doe_data = mass_doe_data.set_index('school_code')\n",
    "float_columns = [c for c in mass_doe_data if c != 'prior_performance']\n",
    "mass_doe_data[float_columns] = mass_doe_data[float_columns].astype(float)\n",
    "mass_doe_data['prior_performance'] = mass_doe_data['prior_performance'].apply(lambda x: np.array(eval(x.replace('nan', 'np.nan'))))\n",
    "mass_doe_data = mass_doe_data.sort_values('school_code')\n",
    "\n",
    "performance_data = pd.read_csv('input_data/performance.csv', dtype=str).astype(str)\n",
    "performance_data = performance_data.set_index('school_code')\n",
    "performance_data = performance_data.astype(float)\n",
    "performance_data = performance_data / 100\n",
    "performance_data = performance_data.sort_values('school_code')\n",
    "\n",
    "# Remnant data\n",
    "\n",
    "remnant_mass_doe_data = mass_doe_data[mass_doe_data.index.isin(remnant_schools)]\n",
    "remnant_performance_data = performance_data[performance_data.index.isin(remnant_schools)]\n",
    "remnant_demographics = remnant_mass_doe_data.drop(columns=['prior_performance']).values\n",
    "remnant_prior_performance = np.array(remnant_mass_doe_data['prior_performance'].tolist())\n",
    "remnant_performance = remnant_performance_data['performance'].values\n",
    "remnant_school_codes = np.array(remnant_performance_data.index)\n",
    "print(remnant_demographics.shape, remnant_prior_performance.shape, remnant_performance.shape, remnant_school_codes.shape)\n",
    "\n",
    "# Experiment data\n",
    "\n",
    "experiment_mass_doe_data = mass_doe_data[mass_doe_data.index.isin(treatment_schools + control_schools)]\n",
    "experiment_performance_data = performance_data[performance_data.index.isin(treatment_schools + control_schools)]\n",
    "experiment_demographics = experiment_mass_doe_data.drop(columns=['prior_performance']).values\n",
    "experiment_prior_performance = np.array(experiment_mass_doe_data['prior_performance'].tolist())\n",
    "experiment_performance = experiment_performance_data['performance'].values\n",
    "experiment_school_codes = np.array(experiment_performance_data.index)\n",
    "print(experiment_demographics.shape, experiment_prior_performance.shape, experiment_performance.shape, experiment_school_codes.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd3204b8160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd300218b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MSE: 0.014685344735943491\n"
     ]
    }
   ],
   "source": [
    "# Get model quality using k-fold on remnant\n",
    "\n",
    "ff_X = remnant_demographics\n",
    "lstm_X = remnant_prior_performance\n",
    "y = remnant_performance\n",
    "i = remnant_school_codes\n",
    "\n",
    "results = []\n",
    "for train_index, test_index in KFold(n_splits=10, shuffle=True).split(ff_X, y):\n",
    "\n",
    "    # Clear session so models don't pile up\n",
    "    keras.backend.clear_session()\n",
    "\n",
    "    # Split data into training and testing splits\n",
    "    train_ff_X, test_ff_X = ff_X[train_index], ff_X[test_index]\n",
    "    train_lstm_X, test_lstm_X = lstm_X[train_index], lstm_X[test_index]\n",
    "    train_y, test_y = y[train_index], y[test_index]\n",
    "    train_i, test_i = i[train_index], i[test_index]\n",
    "\n",
    "    # Normalize the input data based on the training data distribution\n",
    "    ff_scaler = StandardScaler().fit(train_ff_X)\n",
    "    train_ff_X = np.nan_to_num(ff_scaler.transform(train_ff_X))\n",
    "    test_ff_X = np.nan_to_num(ff_scaler.transform(test_ff_X))\n",
    "\n",
    "    train_lstm_X_shape = train_lstm_X.shape\n",
    "    train_stacked_lstm_X = train_lstm_X.reshape(-1, train_lstm_X_shape[-1])\n",
    "    lstm_scaler = StandardScaler().fit(train_stacked_lstm_X)\n",
    "    train_lstm_X = np.nan_to_num(lstm_scaler.transform(train_stacked_lstm_X)).reshape(train_lstm_X_shape)\n",
    "    test_lstm_X_shape = test_lstm_X.shape\n",
    "    test_stacked_lstm_X = test_lstm_X.reshape(-1, test_lstm_X_shape[-1])\n",
    "    test_lstm_X = np.nan_to_num(lstm_scaler.transform(test_stacked_lstm_X)).reshape(test_lstm_X_shape)\n",
    "\n",
    "    # Create the neural network\n",
    "    ff_input_layer = Input(shape=train_ff_X[0].shape)\n",
    "    lstm_input_layer = Input(shape=train_lstm_X[0].shape)\n",
    "    combined_input_layer = RepeatVector(train_lstm_X.shape[1])(ff_input_layer)\n",
    "    combined_input_layer = Concatenate()([combined_input_layer, lstm_input_layer])\n",
    "\n",
    "    model = Bidirectional(LSTM(units=64, return_sequences=False, activation='tanh'))(combined_input_layer)\n",
    "    output_layer = Dense(units=1, activation='sigmoid')(model)\n",
    "\n",
    "    model = Model([ff_input_layer, lstm_input_layer], output_layer)\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    # Train the neural network\n",
    "    es = [EarlyStopping(monitor='val_loss', patience=10, min_delta=0, restore_best_weights=True)]\n",
    "    model.fit(x=[train_ff_X, train_lstm_X], y=train_y, batch_size=16, epochs=1000, validation_split=0.25, callbacks=es, verbose=0)\n",
    "\n",
    "    # Use the neural network to predict the held-out fold\n",
    "    pred_y = model.predict([test_ff_X, test_lstm_X], verbose=0).flatten()\n",
    "\n",
    "    # Update predictions\n",
    "    results.append(pd.DataFrame([test_y, pred_y], columns=test_i, index=['actual_performance', 'predicted_performance']).T)\n",
    "\n",
    "results = pd.concat(results)\n",
    "results.index.name = 'school_code'\n",
    "results.to_csv('results/kfold_remnant_predictions.csv')\n",
    "print(f'MSE: {mean_squared_error(results.actual_performance, results.predicted_performance)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions for experiment data\n",
    "\n",
    "train_ff_X = remnant_demographics\n",
    "train_lstm_X = remnant_prior_performance\n",
    "train_y = remnant_performance\n",
    "train_i = remnant_school_codes\n",
    "\n",
    "test_ff_X = experiment_demographics\n",
    "test_lstm_X = experiment_prior_performance\n",
    "test_y = experiment_performance\n",
    "test_i = experiment_school_codes\n",
    "\n",
    "# Clear session so models don't pile up\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# Normalize the input data based on the training data distribution\n",
    "ff_scaler = StandardScaler().fit(train_ff_X)\n",
    "train_ff_X = np.nan_to_num(ff_scaler.transform(train_ff_X))\n",
    "test_ff_X = np.nan_to_num(ff_scaler.transform(test_ff_X))\n",
    "\n",
    "train_lstm_X_shape = train_lstm_X.shape\n",
    "train_stacked_lstm_X = train_lstm_X.reshape(-1, train_lstm_X_shape[-1])\n",
    "lstm_scaler = StandardScaler().fit(train_stacked_lstm_X)\n",
    "train_lstm_X = np.nan_to_num(lstm_scaler.transform(train_stacked_lstm_X)).reshape(train_lstm_X_shape)\n",
    "test_lstm_X_shape = test_lstm_X.shape\n",
    "test_stacked_lstm_X = test_lstm_X.reshape(-1, test_lstm_X_shape[-1])\n",
    "test_lstm_X = np.nan_to_num(lstm_scaler.transform(test_stacked_lstm_X)).reshape(test_lstm_X_shape)\n",
    "\n",
    "# Create the neural network\n",
    "ff_input_layer = Input(shape=train_ff_X[0].shape)\n",
    "lstm_input_layer = Input(shape=train_lstm_X[0].shape)\n",
    "combined_input_layer = RepeatVector(train_lstm_X.shape[1])(ff_input_layer)\n",
    "combined_input_layer = Concatenate()([combined_input_layer, lstm_input_layer])\n",
    "\n",
    "model = Bidirectional(LSTM(units=64, return_sequences=False, activation='tanh'))(combined_input_layer)\n",
    "output_layer = Dense(units=1, activation='sigmoid')(model)\n",
    "\n",
    "model = Model([ff_input_layer, lstm_input_layer], output_layer)\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the neural network\n",
    "es = [EarlyStopping(monitor='val_loss', patience=10, min_delta=0, restore_best_weights=True)]\n",
    "model.fit(x=[train_ff_X, train_lstm_X], y=train_y, batch_size=16, epochs=1000, validation_split=0.25, callbacks=es, verbose=0)\n",
    "\n",
    "# Use the neural network to predict the held-out fold\n",
    "pred_y = model.predict([test_ff_X, test_lstm_X], verbose=0).flatten()\n",
    "\n",
    "# Update predictions\n",
    "results = pd.DataFrame([test_y, pred_y], columns=test_i, index=['actual_performance', 'predicted_performance']).T\n",
    "results.index.name = 'school_code'\n",
    "results.to_csv('results/experiment_predictions.csv')\n",
    "#print(f'MSE: {mean_squared_error(results.actual_performance, results.predicted_performance)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Input, RepeatVector, Dense, Bidirectional, LSTM, Concatenate\n",
    "\n",
    "# Hide GPU from visible devices\n",
    "tf.config.set_visible_devices([], 'GPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "521 37 37 447 521\n"
     ]
    }
   ],
   "source": [
    "# Get groups of schools\n",
    "\n",
    "matches = pd.read_csv('input_data/matches.csv', dtype=str)\n",
    "treatment_schools = matches[matches['trt'] == '1']['school_code'].tolist()\n",
    "control_schools = matches[(matches['trt'] != '1') & (~matches['pairmatch'].isna())]['school_code'].tolist()\n",
    "remnant_schools = matches[matches['pairmatch'].isna()]['school_code'].tolist()\n",
    "print(len(matches), len(treatment_schools), len(control_schools), len(remnant_schools), len(treatment_schools) + len(control_schools) + len(remnant_schools))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(447, 69) (447, 5, 51) (447,) (447,)\n",
      "(74, 69) (74, 5, 51) (74,) (74,)\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "\n",
    "mass_doe_data = pd.read_csv('input_data/mass_doe_data.csv', dtype=str).astype(str)\n",
    "mass_doe_data = mass_doe_data.set_index('school_code')\n",
    "float_columns = [c for c in mass_doe_data if c != 'prior_performance']\n",
    "mass_doe_data[float_columns] = mass_doe_data[float_columns].astype(float)\n",
    "mass_doe_data['prior_performance'] = mass_doe_data['prior_performance'].apply(lambda x: np.array(eval(x.replace('nan', 'np.nan'))))\n",
    "mass_doe_data = mass_doe_data.sort_values('school_code')\n",
    "\n",
    "performance_data = pd.read_csv('input_data/performance.csv', dtype=str).astype(str)\n",
    "performance_data = performance_data.set_index('school_code')\n",
    "performance_data = performance_data.astype(float)\n",
    "performance_data = performance_data / 100\n",
    "performance_data = performance_data.sort_values('school_code')\n",
    "\n",
    "# Remnant data\n",
    "\n",
    "remnant_mass_doe_data = mass_doe_data[mass_doe_data.index.isin(remnant_schools)]\n",
    "remnant_performance_data = performance_data[performance_data.index.isin(remnant_schools)]\n",
    "remnant_demographics = remnant_mass_doe_data.drop(columns=['prior_performance']).values\n",
    "remnant_prior_performance = np.array(remnant_mass_doe_data['prior_performance'].tolist())\n",
    "remnant_performance = remnant_performance_data['performance'].values\n",
    "remnant_school_codes = np.array(remnant_performance_data.index)\n",
    "print(remnant_demographics.shape, remnant_prior_performance.shape, remnant_performance.shape, remnant_school_codes.shape)\n",
    "\n",
    "# Experiment data\n",
    "\n",
    "experiment_mass_doe_data = mass_doe_data[mass_doe_data.index.isin(treatment_schools + control_schools)]\n",
    "experiment_performance_data = performance_data[performance_data.index.isin(treatment_schools + control_schools)]\n",
    "experiment_demographics = experiment_mass_doe_data.drop(columns=['prior_performance']).values\n",
    "experiment_prior_performance = np.array(experiment_mass_doe_data['prior_performance'].tolist())\n",
    "experiment_performance = experiment_performance_data['performance'].values\n",
    "experiment_school_codes = np.array(experiment_performance_data.index)\n",
    "print(experiment_demographics.shape, experiment_prior_performance.shape, experiment_performance.shape, experiment_school_codes.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "19/19 [==============================] - 7s 50ms/step - loss: 0.0175 - val_loss: 0.0295\n",
      "Epoch 2/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0091 - val_loss: 0.0273\n",
      "Epoch 3/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0075 - val_loss: 0.0267\n",
      "Epoch 4/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0067 - val_loss: 0.0269\n",
      "Epoch 5/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0051 - val_loss: 0.0287\n",
      "Epoch 6/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0052 - val_loss: 0.0247\n",
      "Epoch 7/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0052 - val_loss: 0.0251\n",
      "Epoch 8/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0037 - val_loss: 0.0283\n",
      "Epoch 9/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0041 - val_loss: 0.0241\n",
      "Epoch 10/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.0041 - val_loss: 0.0271\n",
      "Epoch 11/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0036 - val_loss: 0.0236\n",
      "Epoch 12/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0045 - val_loss: 0.0245\n",
      "Epoch 13/1000\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.0022"
     ]
    }
   ],
   "source": [
    "# Get model quality using k-fold on remnant\n",
    "\n",
    "ff_X = remnant_demographics\n",
    "lstm_X = remnant_prior_performance\n",
    "y = remnant_performance\n",
    "i = remnant_school_codes\n",
    "\n",
    "results = []\n",
    "for train_index, test_index in KFold(n_splits=10, shuffle=True).split(ff_X, y):\n",
    "\n",
    "    # Clear session so models don't pile up\n",
    "    keras.backend.clear_session()\n",
    "\n",
    "    # Split data into training and testing splits\n",
    "    train_ff_X, test_ff_X = ff_X[train_index], ff_X[test_index]\n",
    "    train_lstm_X, test_lstm_X = lstm_X[train_index], lstm_X[test_index]\n",
    "    train_y, test_y = y[train_index], y[test_index]\n",
    "    train_i, test_i = i[train_index], i[test_index]\n",
    "\n",
    "    # Normalize the input data based on the training data distribution\n",
    "    ff_scaler = StandardScaler().fit(train_ff_X)\n",
    "    train_ff_X = np.nan_to_num(ff_scaler.transform(train_ff_X))\n",
    "    test_ff_X = np.nan_to_num(ff_scaler.transform(test_ff_X))\n",
    "\n",
    "    train_lstm_X_shape = train_lstm_X.shape\n",
    "    train_stacked_lstm_X = train_lstm_X.reshape(-1, train_lstm_X_shape[-1])\n",
    "    lstm_scaler = StandardScaler().fit(train_stacked_lstm_X)\n",
    "    train_lstm_X = np.nan_to_num(lstm_scaler.transform(train_stacked_lstm_X)).reshape(train_lstm_X_shape)\n",
    "    test_lstm_X_shape = test_lstm_X.shape\n",
    "    test_stacked_lstm_X = test_lstm_X.reshape(-1, test_lstm_X_shape[-1])\n",
    "    test_lstm_X = np.nan_to_num(lstm_scaler.transform(test_stacked_lstm_X)).reshape(test_lstm_X_shape)\n",
    "\n",
    "    # Create the neural network\n",
    "    ff_input_layer = Input(shape=train_ff_X[0].shape)\n",
    "    lstm_input_layer = Input(shape=train_lstm_X[0].shape)\n",
    "    combined_input_layer = RepeatVector(train_lstm_X.shape[1])(ff_input_layer)\n",
    "    combined_input_layer = Concatenate()([combined_input_layer, lstm_input_layer])\n",
    "\n",
    "    model = Bidirectional(LSTM(units=128, return_sequences=True, activation='tanh', dropout=0.5, recurrent_dropout=0.5))(combined_input_layer)\n",
    "    model = Bidirectional(LSTM(units=64, return_sequences=False, activation='tanh', dropout=0.5, recurrent_dropout=0.5))(model)\n",
    "    output_layer = Dense(units=1, activation='sigmoid')(model)\n",
    "\n",
    "    model = Model([ff_input_layer, lstm_input_layer], output_layer)\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    # Train the neural network\n",
    "    es = [EarlyStopping(monitor='val_loss', patience=10, min_delta=0, restore_best_weights=True)]\n",
    "    model.fit(x=[train_ff_X, train_lstm_X], y=train_y, batch_size=16, epochs=1000, validation_split=0.25, callbacks=es, verbose=1)\n",
    "\n",
    "    # Use the neural network to predict the held-out fold\n",
    "    pred_y = model.predict([test_ff_X, test_lstm_X]).flatten()\n",
    "\n",
    "    # Update predictions\n",
    "    results.append(pd.DataFrame([test_y, pred_y], columns=test_i, index=['actual_performance', 'predicted_performance']).T)\n",
    "\n",
    "results = pd.concat(results)\n",
    "results.to_csv('results/kfold_remnant_predictions.csv')\n",
    "print(f'MSE: {mean_squared_error(results.actual_performance, results.predicted_performance)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Mean Prediction MSE: 433.9361577972904\n",
    "\n",
    "(layers)     , dropout , batch size: MSE\n",
    "\n",
    "(64, 32)     , 0       , 32        : 261.0934134399656\n",
    "(32)         , 0       , 32        : 408.9117164445174\n",
    "(64, 32)     , 0.5     , 32        : 227.8827418178931\n",
    "(64, 64)     , 0.25    , 32        : 213.6578965631596\n",
    "(64, 64, 64) , 0.25    , 32        : 264.9091609712526\n",
    "(128, 64)    , 0.5     , 32        : 170.0072276619494\n",
    "(128, 64)    , 0.5     , 16        : 163.5255262041347 / 199.23285354558072 / 145.4 /\n",
    "(128, 64)    , 0.5     , 8         : 183.8387565630688\n",
    "(256, 256)   , 0.5     , 16        : 163.1883336295512\n",
    "(128, 128)   , 0.5     , 16        : 172.0166126039364\n",
    "(256, 128)   , 0.5     , 16        : 177.0513539259982\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "21/21 [==============================] - 8s 50ms/step - loss: 3093.1406 - val_loss: 3505.5574\n",
      "Epoch 2/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 2243.9429 - val_loss: 2446.9783\n",
      "Epoch 3/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 1612.6228 - val_loss: 2048.4456\n",
      "Epoch 4/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 1377.0444 - val_loss: 1818.3348\n",
      "Epoch 5/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 1194.1477 - val_loss: 1705.1327\n",
      "Epoch 6/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 1044.8142 - val_loss: 1572.9720\n",
      "Epoch 7/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 922.5765 - val_loss: 1429.0734\n",
      "Epoch 8/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 822.8928 - val_loss: 1311.6455\n",
      "Epoch 9/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 739.4445 - val_loss: 1213.5487\n",
      "Epoch 10/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 666.3168 - val_loss: 1090.6622\n",
      "Epoch 11/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 602.6083 - val_loss: 1035.8710\n",
      "Epoch 12/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 538.6808 - val_loss: 931.2534\n",
      "Epoch 13/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 486.0420 - val_loss: 857.8110\n",
      "Epoch 14/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 434.0420 - val_loss: 843.7471\n",
      "Epoch 15/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 390.4152 - val_loss: 792.0374\n",
      "Epoch 16/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 349.2168 - val_loss: 755.4573\n",
      "Epoch 17/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 316.7230 - val_loss: 753.7331\n",
      "Epoch 18/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 286.6571 - val_loss: 620.5076\n",
      "Epoch 19/1000\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 258.7589 - val_loss: 592.6693\n",
      "Epoch 20/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 233.9746 - val_loss: 572.2278\n",
      "Epoch 21/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 215.3357 - val_loss: 511.1629\n",
      "Epoch 22/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 196.4931 - val_loss: 513.6128\n",
      "Epoch 23/1000\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 177.6215 - val_loss: 480.5354\n",
      "Epoch 24/1000\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 161.4706 - val_loss: 449.4392\n",
      "Epoch 25/1000\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 148.5167 - val_loss: 435.9600\n",
      "Epoch 26/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 142.1270 - val_loss: 409.8691\n",
      "Epoch 27/1000\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 129.8648 - val_loss: 416.3831\n",
      "Epoch 28/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 124.3430 - val_loss: 417.4563\n",
      "Epoch 29/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 115.8599 - val_loss: 403.0181\n",
      "Epoch 30/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 99.9397 - val_loss: 426.0617\n",
      "Epoch 31/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 96.5589 - val_loss: 392.7026\n",
      "Epoch 32/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 90.9213 - val_loss: 410.4089\n",
      "Epoch 33/1000\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 85.9271 - val_loss: 399.8692\n",
      "Epoch 34/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 76.8949 - val_loss: 415.9807\n",
      "Epoch 35/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 72.2696 - val_loss: 413.9168\n",
      "Epoch 36/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 71.4458 - val_loss: 419.3895\n",
      "Epoch 37/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 64.8310 - val_loss: 422.6818\n",
      "Epoch 38/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 60.4309 - val_loss: 357.0091\n",
      "Epoch 39/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 59.6574 - val_loss: 433.9367\n",
      "Epoch 40/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 53.4723 - val_loss: 434.6635\n",
      "Epoch 41/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 52.9380 - val_loss: 410.8906\n",
      "Epoch 42/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 46.8576 - val_loss: 435.1959\n",
      "Epoch 43/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 44.6630 - val_loss: 414.6152\n",
      "Epoch 44/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 41.1542 - val_loss: 455.9659\n",
      "Epoch 45/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 41.9411 - val_loss: 438.1388\n",
      "Epoch 46/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 41.2189 - val_loss: 430.6057\n",
      "Epoch 47/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 39.6940 - val_loss: 431.3824\n",
      "Epoch 48/1000\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 36.3307 - val_loss: 420.0424\n",
      "MSE: 100.23964504026503\n"
     ]
    }
   ],
   "source": [
    "# Get predictions for experiment data\n",
    "\n",
    "train_ff_X = remnant_demographics\n",
    "train_lstm_X = remnant_prior_performance\n",
    "train_y = remnant_performance\n",
    "train_i = remnant_school_codes\n",
    "\n",
    "test_ff_X = experiment_demographics\n",
    "test_lstm_X = experiment_prior_performance\n",
    "test_y = experiment_performance\n",
    "test_i = experiment_school_codes\n",
    "\n",
    "# Clear session so models don't pile up\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# Normalize the input data based on the training data distribution\n",
    "ff_scaler = StandardScaler().fit(train_ff_X)\n",
    "train_ff_X = np.nan_to_num(ff_scaler.transform(train_ff_X))\n",
    "test_ff_X = np.nan_to_num(ff_scaler.transform(test_ff_X))\n",
    "\n",
    "train_lstm_X_shape = train_lstm_X.shape\n",
    "train_stacked_lstm_X = train_lstm_X.reshape(-1, train_lstm_X_shape[-1])\n",
    "lstm_scaler = StandardScaler().fit(train_stacked_lstm_X)\n",
    "train_lstm_X = np.nan_to_num(lstm_scaler.transform(train_stacked_lstm_X)).reshape(train_lstm_X_shape)\n",
    "test_lstm_X_shape = test_lstm_X.shape\n",
    "test_stacked_lstm_X = test_lstm_X.reshape(-1, test_lstm_X_shape[-1])\n",
    "test_lstm_X = np.nan_to_num(lstm_scaler.transform(test_stacked_lstm_X)).reshape(test_lstm_X_shape)\n",
    "\n",
    "# Create the neural network\n",
    "ff_input_layer = Input(shape=train_ff_X[0].shape)\n",
    "lstm_input_layer = Input(shape=train_lstm_X[0].shape)\n",
    "combined_input_layer = RepeatVector(train_lstm_X.shape[1])(ff_input_layer)\n",
    "combined_input_layer = Concatenate()([combined_input_layer, lstm_input_layer])\n",
    "\n",
    "model = Bidirectional(LSTM(units=128, return_sequences=True, activation='tanh', dropout=0.5, recurrent_dropout=0.5))(combined_input_layer)\n",
    "model = Bidirectional(LSTM(units=64, return_sequences=False, activation='tanh', dropout=0.5, recurrent_dropout=0.5))(model)\n",
    "output_layer = Dense(units=1, activation='sigmoid')(model)\n",
    "\n",
    "model = Model([ff_input_layer, lstm_input_layer], output_layer)\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the neural network\n",
    "es = [EarlyStopping(monitor='val_loss', patience=10, min_delta=0, restore_best_weights=True)]\n",
    "model.fit(x=[train_ff_X, train_lstm_X], y=train_y, batch_size=16, epochs=1000, validation_split=0.25, callbacks=es, verbose=1)\n",
    "\n",
    "# Use the neural network to predict the held-out fold\n",
    "pred_y = model.predict([test_ff_X, test_lstm_X]).flatten()\n",
    "\n",
    "# Update predictions\n",
    "results = pd.DataFrame([test_y, pred_y], columns=test_i, index=['actual_performance', 'predicted_performance']).T\n",
    "results.to_csv('results/experiment_predictions.csv')\n",
    "print(f'MSE: {mean_squared_error(results.actual_performance, results.predicted_performance)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
